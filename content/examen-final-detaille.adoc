= Projet de fin de module DevOps - Docker
Bruno Verachten <gounthar@gmail.com>
v3.0, 8 d√©cembre 2025
:doctype: article
:encoding: utf-8
:lang: fr
:toc: left
:toclevels: 3
:sectnums:
:sectnumlevels: 4
:icons: font
:source-highlighter: highlight.js
:highlightjsdir: highlightjs
:highlightjs-languages: groovy, dockerfile, yaml, json, bash, java, javascript, xml, sql, properties, markdown, plaintext, diff, http, apache
:imagesdir: media/
:sourcedir: code-samples/
:allow-uri-read:
:linkattrs:
:experimental:

[IMPORTANT]
====
**Date limite de rendu : 4 janvier 2026**

Seuls les commits ant√©rieurs √† cette date seront pris en compte pour la correction.
====

== Introduction

=== Pr√©sentation g√©n√©rale

Ce document d√©crit le projet de fin de module pour le cours **DevOps - Docker** du Master 2 ILI, ann√©e universitaire 2025-2026.

Le projet se d√©compose en **deux parties distinctes** :

* **Partie 1** : Infrastructure Docker (not√©e sur 10 points)
* **Partie 2** : Pipeline CI/CD (not√©e sur 10 points)

**Note finale = Partie 1 + Partie 2 = /20**

Ce document d√©taille uniquement la **Partie 1 - Infrastructure Docker**.

=== Modalit√©s

==== Travail en bin√¥me

* Le projet est **obligatoirement** r√©alis√© en bin√¥me
* Les bin√¥mes seront constitu√©s au d√©but du projet
* Les deux membres du bin√¥me recevront la m√™me note

==== Repository GitLab

Vous devez cr√©er un repository **priv√©** sur l'instance GitLab de l'universit√© avec les caract√©ristiques suivantes :

* Repository **priv√©** (pas public)
* Les enseignants ajout√©s en tant que **Maintainer** :
** Bruno Verachten (gounthar)
** Daniel Le Berre
** Farid Ait-Kara
* Documentation compl√®te dans le `README.md`
* Respect des bonnes pratiques Git (commits atomiques, branches, merge requests)

[WARNING]
====
**Communication importante :**

Pour que nous soyons notifi√©s de vos demandes :

* Cr√©ez des **Merge Requests** (MR) et ajoutez-nous en reviewers
* Cr√©ez des **Issues** pour les questions techniques
* **Ne commitez PAS directement sur `main`** sans MR

Les commits directs sur `main` ne g√©n√®rent pas de notification !
====

==== Choix des technologies

Le choix des technologies (reverse-proxy, serveur d'application) sera effectu√© via un **vote sur Moodle** en d√©but de projet.

==== Date limite

**4 janvier 2026** - 23h59

Seuls les commits effectu√©s avant cette date seront corrig√©s. Aucune exception ne sera accord√©e. Les commits ne mentent pas.

=== Objectifs p√©dagogiques

Ce projet a pour objectif de vous pr√©parer aux pratiques professionnelles DevOps modernes en vous permettant de :

* Concevoir et d√©ployer une **architecture multi-tiers** compl√®te avec Docker
* Appliquer les **bonnes pratiques de s√©curit√©** et d'optimisation
* Documenter et justifier vos **choix techniques**
* Mettre en ≈ìuvre des **outils modernes** d'observabilit√© et de qualit√©
* Communiquer efficacement via Git et les outils collaboratifs

[NOTE]
====
**Notre philosophie :**

L'objectif est de vous **pr√©parer** √† l'entreprise, pas de vous **pi√©ger** !

N'h√©sitez pas √† :

* Poser des questions (via Issues GitLab ou MR, ou encore Mattermost ou par email)
* Demander des clarifications
* √âventuellement, solliciter une review interm√©diaire
====

== Architecture cible

=== Vue d'ensemble

Vous allez cr√©er une architecture **production-ready** conteneuris√©e qui d√©ploie une application Java EE compl√®te.

L'architecture comporte **4 composants principaux** :

[plantuml, architecture-exam, png]
----
@startuml
!theme plain

rectangle "Client Web" as client #LightBlue

rectangle "Reverse Proxy\n(Nginx/Apache/Traefik/...)" as proxy #Orange

rectangle "Serveur d'Application\n(Tomcat/Wildfly/Jetty)" as app #Green

database "Base de Donn√©es\n(PostgreSQL/MySQL)" as db #Yellow

rectangle "Stack ELK" as elk #Purple {
  component "Elasticsearch" as es
  component "Logstash" as ls
  component "Kibana" as kb
}

client --> proxy : "HTTP/HTTPS"
proxy --> app : "Proxy pass"
app --> db : "JDBC"
app --> ls : "Logs"
proxy --> ls : "Logs"
ls --> es : "Indexation"
es --> kb : "Visualisation"

@enduml
----

=== Composants obligatoires

==== 1. Reverse-Proxy

**Choix √† faire parmi :**

* Apache HTTPd
* Nginx
* Nginx Unit
* HAProxy
* Traefik
* Caddy

**R√¥le :**

* Point d'entr√©e unique de l'architecture
* Terminaison SSL/TLS (si HTTPS impl√©ment√©)
* Load-balancing si plusieurs instances du serveur d'application
* Routage des requ√™tes vers le serveur d'application

**Crit√®res de choix :**

Justifiez votre choix dans le README en fonction de crit√®res comme :

* Performance
* Facilit√© de configuration
* Support natif de certaines fonctionnalit√©s (ex: ACME pour Caddy, service mesh pour Traefik)
* Exp√©rience personnelle ou curiosit√© technique

==== 2. Serveur d'application Java EE

**Choix √† faire parmi :**

* Apache Tomcat
* Wildfly (anciennement JBoss)
* Jetty

**R√¥le :**

* H√©berger et ex√©cuter l'application web (fichier WAR)
* G√©rer les sessions utilisateurs
* Communiquer avec la base de donn√©es via JDBC
* Exposer l'application sur un port interne (non expos√© directement)

**Application :**

Vous devez d√©ployer un fichier WAR fonctionnel. Vous pouvez :

* Utiliser un exemple fourni dans ce module de cours, dans sa seconde partie, ou dans le cours de M. Leberre.
* Cr√©er votre propre application simple (ex: CRUD basique)
* Utiliser une application open-source (ex: Jenkins, Nexus, etc.)

[IMPORTANT]
====
L'application doit :

* Se connecter √† la base de donn√©es
* √ätre fonctionnelle et accessible via le reverse-proxy
* Avoir au minimum une page d'accueil et une action m√©tier (CRUD, calcul, etc.)
====

==== 3. Base de donn√©es

**Choix √† faire parmi :**

* PostgreSQL (recommand√©)
* MySQL

**R√¥le :**

* Stockage persistant des donn√©es applicatives
* Isolation r√©seau (non expos√©e directement √† l'ext√©rieur)
* Donn√©es persist√©es via volumes Docker

**Exigences :**

* Volumes **nomm√©s** (pas de volumes anonymes)
* Health checks configur√©s
* Credentials g√©r√©s via variables d'environnement (pas en dur)
* Script d'initialisation optionnel (schema SQL)

==== 4. Stack ELK

**Composants :**

* **Elasticsearch** : Moteur de recherche et d'indexation des logs
* **Logstash** : Collecteur et transformateur de logs
* **Kibana** : Interface de visualisation et d'analyse

**R√¥le :**

* Centraliser les logs de tous les services
* Fournir des dashboards de monitoring
* Permettre la recherche et l'analyse des logs

**Exigences minimales :**

* Les logs du reverse-proxy et du serveur d'application doivent √™tre envoy√©s √† Logstash
* Elasticsearch doit indexer ces logs
* Kibana doit √™tre accessible et afficher au moins un dashboard basique
* Les logs doivent √™tre au format JSON quand c'est possible

=== D√©ploiement

L'ensemble de l'architecture doit pouvoir se d√©marrer avec une seule commande :

[source,bash]
----
docker compose up -d
----

**Temps de d√©marrage attendu :** < 2 minutes

Tous les services doivent √™tre "healthy" apr√®s ce d√©lai.

== Exigences techniques d√©taill√©es

=== 1. Docker Compose

==== Structure du fichier

Votre fichier `docker-compose.yml` doit √™tre :

* **Bien structur√©** : utilisation de l'indentation YAML correcte
* **Lisible** : commentaires pour expliquer les choix non-√©vidents
* **Modulaire** : utilisation de `extends` ou `x-` anchors pour √©viter la duplication

**Exemple de bonne structure :**

[source,yaml]
----
# Ancres YAML pour r√©utiliser des configurations
x-common-healthcheck: &common-healthcheck
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s

x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "3"

services:
  reverse-proxy:
    image: nginx:alpine
    ports:
      - "${PROXY_PORT:-80}:80"
    networks:
      - frontend
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      app-server:
        condition: service_healthy
    healthcheck:
      <<: *common-healthcheck
      test: ["CMD", "nginx", "-t"]
    logging: *default-logging
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M

  # ... autres services
----

==== Variables d'environnement

**Fichier `.env` :**

* Contient TOUTES les variables sensibles (mots de passe, secrets, etc.)
* **NE DOIT PAS** √™tre commit√© dans Git
* Ajout√© au `.gitignore`

**Fichier `.env.example` :**

* Contient un template avec toutes les variables n√©cessaires
* Les valeurs sont des exemples ou des placeholders
* **DOIT** √™tre commit√© dans Git pour guider les utilisateurs

**Exemple de `.env.example` :**

[source,bash]
----
# Port expos√© du reverse-proxy
PROXY_PORT=80

# Configuration base de donn√©es
POSTGRES_DB=myapp
POSTGRES_USER=appuser
POSTGRES_PASSWORD=CHANGEME

# Configuration application
APP_SECRET_KEY=CHANGEME_RANDOM_STRING
APP_ENV=production

# Configuration ELK
ELASTIC_PASSWORD=CHANGEME
KIBANA_PASSWORD=CHANGEME
----

[WARNING]
====
**S√©curit√© :**

* Les mots de passe par d√©faut doivent √™tre chang√©s
* Les secrets ne doivent JAMAIS appara√Ætre en clair dans le `compose.yml`
* Utilisez `${VARIABLE_NAME}` pour r√©f√©rencer les variables
====

==== Networks

Vous devez cr√©er **au minimum 2 r√©seaux** :

* **frontend** : R√©seau expos√© contenant le reverse-proxy
* **backend** : R√©seau priv√© pour la communication base de donn√©es / application

**Exemple :**

[source,yaml]
----
networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
    internal: true  # Pas d'acc√®s externe (optionnel mais recommand√©)
----

**Isolation :**

* Le reverse-proxy est connect√© au r√©seau `frontend`
* Le serveur d'application est connect√© aux r√©seaux `frontend` et `backend`
* La base de donn√©es est connect√©e uniquement au r√©seau `backend`

Cette isolation am√©liore la s√©curit√© en limitant les communications possibles.

==== Volumes

Tous les volumes doivent √™tre **nomm√©s** (pas de volumes anonymes).

**Exemple :**

[source,yaml]
----
volumes:
  postgres_data:
    driver: local
  elasticsearch_data:
    driver: local
----

[IMPORTANT]
====
**Pourquoi des volumes nomm√©s ?**

* √âvite la perte de donn√©es lors de `docker compose down`
* Permet de facilement identifier et g√©rer les volumes
* Facilite les sauvegardes et restaurations
====

=== 2. Images Docker

==== Multi-stage builds

Pour les services construits (pas ceux utilisant des images officielles), vous devez utiliser des **multi-stage builds**.

**Exemple pour une application Java :**

[source,dockerfile]
----
# Stage 1: Build
FROM maven:3.9-eclipse-temurin-17 AS builder

WORKDIR /app
COPY pom.xml .
# T√©l√©charger les d√©pendances (cache Docker layer)
RUN mvn dependency:go-offline

COPY src ./src
RUN mvn package -DskipTests

# Stage 2: Runtime
FROM tomcat:10-jre17-temurin-alpine

# Supprimer les apps par d√©faut de Tomcat
RUN rm -rf /usr/local/tomcat/webapps/*

# Copier le WAR depuis le stage de build
COPY --from=builder /app/target/myapp.war /usr/local/tomcat/webapps/ROOT.war

# Utilisateur non-root (s√©curit√©)
RUN addgroup -g 1001 -S appgroup && \
    adduser -u 1001 -S appuser -G appgroup && \
    chown -R appuser:appgroup /usr/local/tomcat

USER appuser

EXPOSE 8080

CMD ["catalina.sh", "run"]
----

**Avantages :**

* Image finale plus l√©g√®re (pas de Maven, pas de code source)
* S√©paration build / runtime
* Am√©lioration de la s√©curit√©

==== Taille des images

**Crit√®res d'√©valuation :**

* Images applicatives (serveur d'app) : **< 500 MB**
* Images de services (proxy, base de donn√©es) : **< 200 MB**

**Conseils pour r√©duire la taille :**

* Utiliser des images de base Alpine quand possible (`alpine`, `slim`)
* Multi-stage builds
* Nettoyer les caches (`apt-get clean`, `yum clean all`, etc.)
* Utiliser `.dockerignore`

==== Fichier `.dockerignore`

Chaque service avec un Dockerfile doit avoir un `.dockerignore` configur√©.

**Exemple :**

[source]
----
# Git
.git
.gitignore
.gitattributes

# CI/CD
.github
.gitlab-ci.yml

# Documentation
README.md
docs/
*.md

# IDE
.vscode/
.idea/
*.iml

# Build artifacts (pour √©viter de les copier dans l'image)
target/
build/
dist/
node_modules/

# Tests
tests/
test/
*.test.js

# Environnement
.env
.env.*
!.env.example
----

==== Pas de secrets dans les images

[WARNING]
====
**Interdictions absolues :**

* Mots de passe en dur dans les Dockerfiles
* Cl√©s priv√©es (SSH, GPG, etc.) copi√©es dans l'image
* Tokens d'API stock√©s dans le code source
* Fichiers `.env` copi√©s dans l'image

**Bonne pratique :**

* Utiliser des variables d'environnement pass√©es au runtime
* Utiliser Docker Secrets (pour Swarm) ou des outils externes (Vault)
* V√©rifier avec `docker history <image>` qu'aucun secret n'est visible
====

=== 3. Health Checks

==== Sur tous les services

Chaque service doit avoir un health check configur√©.

**Exemples par type de service :**

**Base de donn√©es PostgreSQL :**

[source,yaml]
----
healthcheck:
  test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
  interval: 10s
  timeout: 5s
  retries: 5
  start_period: 10s
----

**Base de donn√©es MySQL :**

[source,yaml]
----
healthcheck:
  test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD}"]
  interval: 10s
  timeout: 5s
  retries: 5
  start_period: 10s
----

**Serveur d'application (Tomcat) :**

[source,yaml]
----
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s
----

[NOTE]
====
Pour Tomcat, vous devez cr√©er un endpoint `/health` simple qui retourne 200 OK.
Si votre application n'a pas de endpoint d√©di√©, vous pouvez tester la page d'accueil.
====

**Reverse-proxy (Nginx) :**

[source,yaml]
----
healthcheck:
  test: ["CMD", "nginx", "-t"]
  interval: 30s
  timeout: 5s
  retries: 3
  start_period: 10s
----

**Elasticsearch :**

[source,yaml]
----
healthcheck:
  test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
  interval: 30s
  timeout: 10s
  retries: 5
  start_period: 60s
----

==== Restart policies

Chaque service doit avoir une politique de red√©marrage appropri√©e.

**Choix recommand√©s :**

* `unless-stopped` : Pour les services critiques qui doivent toujours tourner
* `on-failure:5` : Pour les services applicatifs (red√©marre max 5 fois en cas d'erreur)

**Exemple :**

[source,yaml]
----
services:
  database:
    # ...
    restart: unless-stopped

  app-server:
    # ...
    restart: on-failure:5
----

==== D√©pendances avec conditions

Utilisez `depends_on` avec la condition `service_healthy` pour orchestrer le d√©marrage.

**Exemple :**

[source,yaml]
----
services:
  app-server:
    # ...
    depends_on:
      database:
        condition: service_healthy

  reverse-proxy:
    # ...
    depends_on:
      app-server:
        condition: service_healthy
----

**Effet :**

* Le serveur d'application ne d√©marre que quand la base de donn√©es est "healthy"
* Le reverse-proxy ne d√©marre que quand le serveur d'application est "healthy"
* √âvite les erreurs de connexion au d√©marrage

=== 4. Resource Management

Chaque service doit avoir des limites de ressources CPU et m√©moire.

**Exemple :**

[source,yaml]
----
services:
  database:
    # ...
    deploy:
      resources:
        limits:
          cpus: '1.0'      # Maximum 1 CPU
          memory: 1024M    # Maximum 1 Go de RAM
        reservations:
          cpus: '0.25'     # R√©servation minimum
          memory: 512M     # R√©servation minimum
----

**Recommandations par service :**

[cols="2,1,1", options="header"]
|===
|Service |CPU Limit |Memory Limit

|Reverse-proxy
|0.5
|256M

|Serveur d'application
|1.0
|1024M

|Base de donn√©es
|1.0
|1024M

|Elasticsearch
|2.0
|2048M

|Logstash
|1.0
|1024M

|Kibana
|1.0
|512M
|===

[NOTE]
====
Ces valeurs sont des recommandations de d√©part. Vous pouvez les ajuster selon :

* Les ressources de votre machine
* Les tests de charge
* Les m√©triques observ√©es
====

=== 5. Logging

==== Format JSON

Les logs doivent √™tre au format JSON quand c'est possible.

**Configuration Docker Compose :**

[source,yaml]
----
services:
  app-server:
    # ...
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=app,env=production"
----

**Rotation des logs :**

* `max-size` : Taille maximale d'un fichier de log (ex: 10m = 10 m√©gaoctets)
* `max-file` : Nombre de fichiers conserv√©s (ex: 3 = logs des 3 derni√®res rotations)

==== Int√©gration Logstash

Les logs doivent √™tre envoy√©s √† Logstash pour centralisation.

**Configuration Logstash (exemple) :**

[source,ruby]
----
input {
  tcp {
    port => 5000
    codec => json
  }
}

filter {
  # Ajout de m√©tadonn√©es
  mutate {
    add_field => { "[@metadata][environment]" => "production" }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "app-logs-%{+YYYY.MM.dd}"
  }
}
----

**Configuration application (Logback pour Java) :**

[source,xml]
----
<configuration>
  <appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
    <destination>logstash:5000</destination>
    <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
  </appender>

  <root level="INFO">
    <appender-ref ref="LOGSTASH" />
  </root>
</configuration>
----

==== Dashboards Kibana

Vous devez cr√©er au moins **un dashboard Kibana basique** avec :

* Graphique de volume de logs par service
* Tableau des derniers logs
* Filtre par niveau (INFO, WARN, ERROR)

=== 6. S√©curit√©

==== Utilisateur non-root

Tous les conteneurs doivent tourner avec un utilisateur **non-root**.

**Dans le Dockerfile :**

[source,dockerfile]
----
# Cr√©er un utilisateur
RUN addgroup -g 1001 -S appgroup && \
    adduser -u 1001 -S appuser -G appgroup

# Changer les permissions
RUN chown -R appuser:appgroup /app

# Passer √† l'utilisateur
USER appuser
----

**Ou dans le docker-compose.yml :**

[source,yaml]
----
services:
  app-server:
    # ...
    user: "1001:1001"
----

**V√©rification :**

[source,bash]
----
# Doit afficher un utilisateur autre que root (uid != 0)
docker compose exec app-server whoami
----

==== Gestion des secrets

**Options recommand√©es :**

1. **Variables d'environnement** (solution simple pour l'exercice)
2. **Docker Secrets** (si vous utilisez Swarm mode)
3. **HashiCorp Vault** (compl√©ment valoris√© avanc√©)

**Exemple avec Docker Secrets :**

[source,yaml]
----
secrets:
  db_password:
    file: ./secrets/db_password.txt

services:
  database:
    # ...
    secrets:
      - db_password
    environment:
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
----

==== Scanning de vuln√©rabilit√©s avec Trivy

Vous devez scanner vos images avec **Trivy**.

**Installation :**

[source,bash]
----
# Linux
curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin

# macOS
brew install trivy

# Docker
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
  aquasec/trivy image myimage:latest
----

**Utilisation :**

[source,bash]
----
# Scanner une image locale
trivy image myapp:latest

# Scanner avec un niveau de s√©v√©rit√© minimum
trivy image --severity HIGH,CRITICAL myapp:latest

# G√©n√©rer un rapport JSON
trivy image -f json -o report.json myapp:latest
----

**Exigence :**

* Aucune vuln√©rabilit√© **CRITICAL** non justifi√©e
* Les vuln√©rabilit√©s **HIGH** doivent √™tre document√©es dans le README

=== 7. Documentation

Le fichier `README.md` doit √™tre **complet et professionnel**.

==== Sections obligatoires

[source,markdown]
----
# Nom du Projet

Description br√®ve du projet (1-2 paragraphes).

## Architecture

### Vue d'ensemble

Diagramme de l'architecture (PlantUML, draw.io, ou autre).

### Composants

Description de chaque composant :
- R√¥le
- Technologies utilis√©es
- Ports expos√©s
- D√©pendances

## Pr√©requis

- Docker >= 24.0
- Docker Compose >= 2.20
- Minimum 8 Go de RAM disponible
- etc.

## Installation

### 1. Cloner le repository

```bash
git clone <url>
cd <project>
```

### 2. Configuration

Copier le fichier d'environnement :

```bash
cp .env.example .env
```

√âditer `.env` et modifier les valeurs :
- `POSTGRES_PASSWORD` : mot de passe de la base de donn√©es
- etc.

### 3. D√©marrage

```bash
docker compose up -d
```

### 4. V√©rification

V√©rifier que tous les services sont "healthy" :

```bash
docker compose ps
```

## Utilisation

### Acc√®s √† l'application

- Application web : http://localhost:8080
- Kibana (logs) : http://localhost:5601

### Comptes par d√©faut

‚ö†Ô∏è √Ä changer en production !

- Kibana : elastic / changeme
- Base de donn√©es : appuser / changeme

## Configuration avanc√©e

(Si applicable : multi-environnements, HA, etc.)

## Tests

(Comment tester que l'application fonctionne)

```bash
# Test du endpoint health
curl http://localhost:8080/health

# Test d'une fonctionnalit√© m√©tier
curl -X POST http://localhost:8080/api/items -d '{"name":"test"}'
```

## Troubleshooting

### Probl√®me : Service ne d√©marre pas

```bash
# Voir les logs du service
docker compose logs -f <service-name>

# Red√©marrer un service sp√©cifique
docker compose restart <service-name>
```

### Probl√®me : Base de donn√©es inaccessible

- V√©rifier le health check : `docker compose ps`
- V√©rifier les credentials dans `.env`
- V√©rifier les logs : `docker compose logs database`

## Choix techniques

### Choix du reverse-proxy : Nginx

Justification :
- Performance excellente
- Configuration simple
- Large communaut√©
- etc.

### Choix du serveur d'application : Tomcat

Justification :
- L√©ger et rapide
- Support natif des WAR
- Bonne int√©gration avec l'√©cosyst√®me Java
- etc.

## Am√©liorations futures

(Optionnel : ce qui pourrait √™tre ajout√©)

## Contributeurs

- Pr√©nom Nom (@username)
- Pr√©nom Nom (@username)

## Licence

(Si applicable)
----

==== Diagramme d'architecture

Vous devez inclure un **diagramme visuel** de l'architecture.

**Outils recommand√©s :**

* PlantUML (g√©n√©ration automatique depuis le code)
* draw.io / diagrams.net
* Mermaid (int√©gr√© dans GitLab/GitHub)
* Excalidraw

**Exemple PlantUML :**

[source,plantuml]
----
@startuml
!theme plain

actor User

rectangle "Docker Compose" {
  component "Nginx" as proxy
  component "Tomcat" as app
  database "PostgreSQL" as db
  component "Elasticsearch" as es
  component "Logstash" as ls
  component "Kibana" as kb
}

User --> proxy : HTTP
proxy --> app
app --> db : JDBC
app --> ls : Logs
proxy --> ls : Logs
ls --> es
es --> kb
User --> kb : Monitoring

@enduml
----

== Grille d'√©valuation

=== Crit√®res principaux (10 points)

La Partie 1 est not√©e sur **10 points** r√©partis selon les crit√®res suivants :

[cols="3,1,5", options="header"]
|===
|Crit√®re |Points |D√©tail

|**Architecture fonctionnelle**
|**3 pts**
a|
* 1 pt : Stack compl√®te d√©ployable avec `docker compose up -d`
* 1 pt : Tous les services sont accessibles et fonctionnels
* 1 pt : Communication entre les services op√©rationnelle

|**Qualit√© technique**
|**3 pts**
a|
* 0.75 pt : Multi-stage builds et images optimis√©es
* 0.75 pt : Health checks et depends_on corrects
* 0.75 pt : Resource limits configur√©s
* 0.75 pt : S√©curit√© (utilisateur non-root, secrets, Trivy)

|**Documentation**
|**2 pts**
a|
* 1 pt : README complet avec architecture, pr√©requis, installation
* 0.5 pt : Diagramme d'architecture clair
* 0.5 pt : Justifications des choix techniques

|**Bonnes pratiques**
|**2 pts**
a|
* 0.5 pt : Images < 500 MB (app) et < 200 MB (services)
* 0.5 pt : Logs structur√©s (JSON) vers Logstash/Kibana
* 0.5 pt : Variables d'environnement (.env), pas de secrets en clair
* 0.5 pt : Networks isol√©s, volumes nomm√©s

|**TOTAL**
|**10 pts**
|
|===

=== Compl√©ments valoris√©s

Les compl√©ments valoris√©s permettent de **compenser les points manquants** et d'atteindre la note maximale de 10/10.

**Formule de calcul :**

----
Note Partie 1 = min(10, Crit√®res principaux + Compl√©ments valoris√©s)
----

**Exemple :**

* 7/10 sur les crit√®res principaux + 2 points de compl√©ments = **9/10**
* 8/10 sur les crit√®res principaux + 3 points de compl√©ments = **10/10** (plafonn√©)

[IMPORTANT]
====
**Strat√©gie recommand√©e : Qualit√© > Quantit√©**

Il vaut mieux :

* **1-2 compl√©ments de qualit√©** (bien impl√©ment√©s, document√©s, fonctionnels)
* Que **4 compl√©ments b√¢cl√©s** (partiellement fonctionnels, non document√©s)

Choisissez les compl√©ments qui **vous int√©ressent** et que vous voulez **approfondir** !
====

==== Compl√©ment 1 : Observabilit√© avec Prometheus + Grafana (+1 pt)

**Objectif :** Mettre en place une stack de monitoring moderne.

**Composants :**

* **Prometheus** : Collecte de m√©triques temps r√©el
* **Grafana** : Visualisation et dashboards
* **Exporters** : cAdvisor (m√©triques Docker), Node Exporter (m√©triques syst√®me)
* **Micrometer** : Biblioth√®que Java pour exposer des m√©triques applicatives

**Crit√®res d'√©valuation :**

* 0.5 pt : Prometheus configur√© et collecte les m√©triques
* 0.25 pt : Dashboard Grafana "syst√®me" (CPU, RAM, r√©seau des conteneurs)
* 0.25 pt : Dashboard Grafana "applicatif" (m√©triques m√©tier, latence, throughput)
* Bonus : Au moins 1 alerte Prometheus configur√©e

**Configuration Prometheus (exemple) :**

[source,yaml]
----
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  # M√©triques Docker via cAdvisor
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']

  # M√©triques syst√®me
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # M√©triques applicatives (si Micrometer configur√©)
  - job_name: 'spring-app'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['app-server:8080']
----

**Int√©gration Micrometer dans Spring Boot :**

[source,xml]
----
<!-- pom.xml -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
----

[source,properties]
----
# application.properties
management.endpoints.web.exposure.include=health,info,prometheus
management.metrics.export.prometheus.enabled=true
----

**Ressources utiles :**

* https://prometheus.io/docs/introduction/overview/
* https://grafana.com/docs/grafana/latest/getting-started/
* https://github.com/google/cadvisor
* https://micrometer.io/docs

==== Compl√©ment 2 : Pipeline de validation avec Goss (+1 pt)

**Objectif :** Automatiser les tests de l'infrastructure Docker.

**Outil :** https://github.com/goss-org/goss[Goss] - Outil de tests d'infrastructure

**Crit√®res d'√©valuation :**

* 0.5 pt : Fichier `goss.yaml` avec tests complets
* 0.25 pt : Pipeline CI/CD qui ex√©cute les tests Goss
* 0.25 pt : Rapport de tests g√©n√©r√© (JUnit XML ou JSON)

**Exemple de tests Goss :**

[source,yaml]
----
# goss.yaml
port:
  tcp:80:
    listening: true
    ip:
      - 0.0.0.0

  tcp:5432:
    listening: true

http:
  http://localhost:80:
    status: 200
    timeout: 5000

  http://localhost:80/health:
    status: 200
    body:
      - '{"status":"UP"}'

docker-container:
  reverse-proxy:
    running: true
    status: "running"

  app-server:
    running: true
    status: "running"
    health-status: "healthy"

  database:
    running: true
    status: "running"
    health-status: "healthy"
----

**Pipeline GitLab CI (exemple) :**

[source,yaml]
----
# .gitlab-ci.yml
test-infrastructure:
  stage: test
  image: docker:24
  services:
    - docker:24-dind
  script:
    - apk add --no-cache curl
    # Installer Goss
    - curl -fsSL https://goss.rocks/install | sh
    # D√©marrer les services
    - docker compose up -d
    # Attendre que les services soient healthy
    - sleep 30
    # Ex√©cuter les tests
    - goss validate --format junit > goss-report.xml
  artifacts:
    reports:
      junit: goss-report.xml
----

**Ressources utiles :**

* https://github.com/goss-org/goss
* https://github.com/aelsabbahy/goss/blob/master/docs/manual.md

==== Compl√©ment 3 : Gestion automatique des d√©pendances (+0.75 pt)

**Objectif :** Automatiser la mise √† jour des d√©pendances (images Docker, d√©pendances Maven, etc.).

**Outils (choisir un) :**

* **Updatecli** (recommand√© pour Docker)
* **Renovate**
* **Dependabot**

**Crit√®res d'√©valuation :**

* 0.5 pt : Configuration fonctionnelle avec au moins 3 d√©pendances surveill√©es
* 0.25 pt : Au moins 1 Pull Request automatique cr√©√©e par l'outil

**Configuration Updatecli (exemple) :**

[source,yaml]
----
# updatecli/updatecli.d/docker-images.yaml
name: "Update Docker images"

sources:
  nginx:
    kind: dockerimage
    spec:
      image: nginx
      tagfilter: "alpine$"

  postgres:
    kind: dockerimage
    spec:
      image: postgres
      tagfilter: "^15-alpine$"

targets:
  docker-compose-nginx:
    name: "Update nginx image in docker-compose.yml"
    kind: yaml
    spec:
      file: docker-compose.yml
      key: services.reverse-proxy.image
    sourceid: nginx

  docker-compose-postgres:
    name: "Update postgres image in docker-compose.yml"
    kind: yaml
    spec:
      file: docker-compose.yml
      key: services.database.image
    sourceid: postgres
----

**Pipeline GitLab CI (exemple) :**

[source,yaml]
----
# .gitlab-ci.yml
updatecli:
  stage: update-dependencies
  image: updatecli/updatecli:latest
  script:
    - updatecli diff --config updatecli/updatecli.d/
    - updatecli apply --config updatecli/updatecli.d/
  only:
    - schedules
----

**Ressources utiles :**

* https://www.updatecli.io/
* https://docs.renovatebot.com/
* https://docs.github.com/en/code-security/dependabot

==== Compl√©ment 4 : Performance & Load Testing (+1 pt)

**Objectif :** Tester les performances de l'application et prouver l'impact des optimisations.

**Outils (choisir un) :**

* **k6** (recommand√©, simple et moderne)
* **Gatling** (plus complet, orient√© Java)

**Crit√®res d'√©valuation :**

* 0.5 pt : Sc√©narios de tests de charge r√©alistes (connexion, CRUD, etc.)
* 0.25 pt : Rapport de performance avec m√©triques cl√©s (throughput, latence, erreurs)
* 0.25 pt : Preuve d'optimisations (comparaison avant/apr√®s)

**Exemple de test k6 :**

[source,javascript]
----
// load-test.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  stages: [
    { duration: '30s', target: 10 },  // Mont√©e √† 10 utilisateurs
    { duration: '1m', target: 50 },   // Mont√©e √† 50 utilisateurs
    { duration: '30s', target: 0 },   // Descente √† 0
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'], // 95% des requ√™tes < 500ms
    http_req_failed: ['rate<0.01'],   // Taux d'erreur < 1%
  },
};

export default function () {
  // Test page d'accueil
  const res = http.get('http://localhost:8080');
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });

  sleep(1);

  // Test API
  const payload = JSON.stringify({
    name: 'Test Item',
    value: Math.random() * 100,
  });
  const params = {
    headers: { 'Content-Type': 'application/json' },
  };
  const apiRes = http.post('http://localhost:8080/api/items', payload, params);
  check(apiRes, {
    'API status is 201': (r) => r.status === 201,
  });

  sleep(1);
}
----

**Ex√©cution :**

[source,bash]
----
# Installer k6
brew install k6  # macOS
# ou
docker pull grafana/k6

# Ex√©cuter le test
k6 run load-test.js

# G√©n√©rer un rapport HTML
k6 run --out json=results.json load-test.js
----

**M√©triques attendues dans le rapport :**

* **Throughput** : requ√™tes/seconde (RPS)
* **Latence** : p50, p95, p99 (percentiles)
* **Taux d'erreur** : % de requ√™tes √©chou√©es
* **Comparaison avant/apr√®s** : prouver l'impact des optimisations (ex: cache Redis, tuning JVM, etc.)

**Ressources utiles :**

* https://k6.io/docs/
* https://gatling.io/docs/

==== Compl√©ment 5 : Haute disponibilit√© (+1 pt)

**Objectif :** D√©ployer plusieurs instances du serveur d'application avec load-balancing.

**Crit√®res d'√©valuation :**

* 0.5 pt : Au moins 2 instances du serveur d'application
* 0.25 pt : Load balancing configur√© sur le reverse-proxy (round-robin ou least-conn)
* 0.25 pt : D√©monstration de zero-downtime deployment (script de rolling update)

**Configuration Docker Compose (scale) :**

[source,yaml]
----
services:
  app-server:
    # ... configuration habituelle
    deploy:
      replicas: 3  # 3 instances

  reverse-proxy:
    # ... configuration habituelle
    depends_on:
      - app-server
----

**Configuration Nginx (load balancing) :**

[source,nginx]
----
# nginx.conf
upstream app_servers {
    least_conn;  # Ou : round_robin, ip_hash
    server app-server-1:8080;
    server app-server-2:8080;
    server app-server-3:8080;
}

server {
    listen 80;

    location / {
        proxy_pass http://app_servers;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;

        # Health check passif
        proxy_next_upstream error timeout http_502 http_503 http_504;
    }
}
----

**Script de rolling update :**

[source,bash]
----
#!/bin/bash
# rolling-update.sh

# Mettre √† jour les instances une par une
for instance in app-server-1 app-server-2 app-server-3; do
  echo "Updating $instance..."

  # Arr√™ter l'instance
  docker compose stop $instance

  # Mettre √† jour l'image
  docker compose pull $instance

  # Red√©marrer l'instance
  docker compose up -d $instance

  # Attendre que l'instance soit healthy
  until [ "$(docker inspect --format='{{.State.Health.Status}}' $instance)" == "healthy" ]; do
    echo "Waiting for $instance to be healthy..."
    sleep 5
  done

  echo "$instance updated successfully"
  sleep 10  # Pause entre les mises √† jour
done

echo "Rolling update completed!"
----

**D√©monstration :**

* Lancer le script de rolling update
* Pendant l'ex√©cution, faire des requ√™tes continues √† l'application (`while true; do curl ...; sleep 1; done`)
* Prouver qu'aucune requ√™te n'√©choue (taux d'erreur = 0%)

**Ressources utiles :**

* https://docs.docker.com/compose/compose-file/deploy/
* https://nginx.org/en/docs/http/load_balancing.html

==== Compl√©ment 6 : Multi-environnements (+0.75 pt)

**Objectif :** G√©rer plusieurs environnements (dev, staging, prod) avec Docker Compose.

**Crit√®res d'√©valuation :**

* 0.5 pt : Au moins 3 environnements avec configurations diff√©rentes
* 0.25 pt : Utilisation de Compose overrides (`compose.override.yml`, `compose.prod.yml`)

**Structure des fichiers :**

[source]
----
project/
‚îú‚îÄ‚îÄ compose.yml              # Configuration de base (commune)
‚îú‚îÄ‚îÄ compose.override.yml     # Dev (charg√© automatiquement)
‚îú‚îÄ‚îÄ compose.staging.yml      # Staging
‚îú‚îÄ‚îÄ compose.prod.yml         # Production
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .env.dev
‚îú‚îÄ‚îÄ .env.staging
‚îî‚îÄ‚îÄ .env.prod
----

**`compose.yml` (base commune) :**

[source,yaml]
----
services:
  app-server:
    build: ./app
    environment:
      - APP_ENV=${APP_ENV}
    networks:
      - backend
----

**`compose.override.yml` (dev - charg√© par d√©faut) :**

[source,yaml]
----
services:
  app-server:
    build:
      context: ./app
      target: dev  # Stage de d√©veloppement
    ports:
      - "8080:8080"  # Exposer pour debug
    volumes:
      - ./app/src:/app/src  # Hot-reload
    environment:
      - DEBUG=true
      - LOG_LEVEL=DEBUG
----

**`compose.prod.yml` (production) :**

[source,yaml]
----
services:
  app-server:
    build:
      context: ./app
      target: production  # Stage optimis√©
    environment:
      - DEBUG=false
      - LOG_LEVEL=WARN
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 1024M
    restart: unless-stopped
----

**Utilisation :**

[source,bash]
----
# Environnement dev (par d√©faut)
docker compose up -d

# Environnement staging
docker compose -f compose.yml -f compose.staging.yml --env-file .env.staging up -d

# Environnement production
docker compose -f compose.yml -f compose.prod.yml --env-file .env.prod up -d
----

**Scripts utiles :**

[source,bash]
----
#!/bin/bash
# deploy.sh

ENV=${1:-dev}

case $ENV in
  dev)
    docker compose up -d
    ;;
  staging)
    docker compose -f compose.yml -f compose.staging.yml --env-file .env.staging up -d
    ;;
  prod)
    docker compose -f compose.yml -f compose.prod.yml --env-file .env.prod up -d
    ;;
  *)
    echo "Usage: $0 {dev|staging|prod}"
    exit 1
    ;;
esac
----

**Ressources utiles :**

* https://docs.docker.com/compose/extends/

== Conseils pratiques

=== Par o√π commencer ?

1. **Choisir les technologies** (vote Moodle)
2. **Cr√©er le repository GitLab** et ajouter les enseignants
3. **Cr√©er un `docker-compose.yml` basique** avec les 4 services
4. **Faire fonctionner l'architecture** (priorit√© absolue)
5. **Ajouter progressivement** : health checks, resource limits, logging
6. **Optimiser les images** : multi-stage builds, `.dockerignore`
7. **S√©curiser** : utilisateur non-root, Trivy, secrets
8. **Documenter au fur et √† mesure** (pas √† la fin !)
9. **Compl√©ments valoris√©s** : uniquement si le temps le permet

[TIP]
====
**Approche it√©rative recommand√©e :**

Ne cherchez pas la perfection du premier coup. Proc√©dez par √©tapes :

1. ‚úÖ Faire fonctionner (m√™me si imparfait)
2. ‚úÖ Am√©liorer progressivement
3. ‚úÖ Documenter chaque √©tape
4. ‚úÖ Merger r√©guli√®rement (petites MR)

C'est exactement comme en entreprise !
====

=== Gestion du temps

**Estimation de temps par t√¢che :**

[cols="3,1", options="header"]
|===
|T√¢che |Dur√©e estim√©e

|Configuration de base (compose.yml, services)
|2-3h

|D√©ploiement de l'application WAR
|1-2h

|Health checks et depends_on
|1h

|Resource limits et logging
|1h

|S√©curit√© (non-root, Trivy)
|1-2h

|Stack ELK (configuration compl√®te)
|2-3h

|Documentation (README complet)
|2-3h

|**Total crit√®res principaux**
|**10-15h**

|Compl√©ment 1 (Observabilit√©)
|3-4h

|Compl√©ment 2 (Goss)
|2-3h

|Compl√©ment 3 (Updatecli)
|2h

|Compl√©ment 4 (Load Testing)
|3-4h

|Compl√©ment 5 (HA)
|3-4h

|Compl√©ment 6 (Multi-env)
|2h
|===

[IMPORTANT]
====
**Priorisez les crit√®res principaux !**

Assurez-vous d'avoir une architecture **fonctionnelle et bien document√©e** avant de vous lancer dans les compl√©ments valoris√©s.

**Mieux vaut :**

* 10/10 sur les crit√®res principaux
* Que 6/10 sur les crit√®res + 4 compl√©ments partiels
====

=== Workflow Git recommand√©

**Branches :**

* `main` : Code stable et fonctionnel uniquement
* `develop` : Branche de d√©veloppement principale
* `feature/<nom>` : Branches pour les nouvelles fonctionnalit√©s
* `fix/<nom>` : Branches pour les corrections de bugs

**Commits :**

Utilisez le format **Conventional Commits** :

[source]
----
feat(compose): add PostgreSQL service with health check
fix(nginx): correct proxy_pass configuration
docs(readme): add architecture diagram
chore(deps): update nginx to 1.25-alpine
----

**Merge Requests :**

* Cr√©ez des MR **petites et focalis√©es**
* Ajoutez les enseignants en reviewers
* D√©crivez clairement ce qui change et pourquoi
* Attendez les retours avant de merger

[TIP]
====
**Exemple de description de MR :**

```markdown
## Description

Ajout du service PostgreSQL avec :
- Volume nomm√© pour la persistance
- Health check bas√© sur `pg_isready`
- Credentials via variables d'environnement

## Checklist

- [x] Service d√©marre correctement
- [x] Health check fonctionnel
- [x] Documentation mise √† jour
- [ ] Tests Goss ajout√©s (pr√©vu dans prochaine MR)

## Captures d'√©cran

(Optionnel mais appr√©ci√©)
```
====

=== Communication avec les enseignants

**Privil√©giez GitLab pour la communication :**

* **Issues** : Pour les questions techniques, blocages, demandes de clarification
* **Merge Requests** : Pour les reviews de code, validation d'approches
* **Comments** : Pour des retours pr√©cis sur du code

**Format d'une bonne issue :**

[source,markdown]
----
## Probl√®me

Le health check de Tomcat √©choue syst√©matiquement apr√®s 40 secondes.

## Ce que j'ai essay√©

1. Augment√© `start_period` √† 60s
2. Test√© manuellement avec `curl http://localhost:8080` ‚Üí fonctionne
3. V√©rifi√© les logs : aucune erreur visible

## Question

Est-ce que le health check doit pointer vers un endpoint sp√©cifique ?
Ou est-ce que la page d'accueil Tomcat par d√©faut suffit ?

## Contexte

- Serveur : Tomcat 10
- OS : Ubuntu 22.04
- Docker : 24.0.6
- Branch : feature/tomcat-healthcheck
----

=== Utilisation de l'IA (ChatGPT, Claude, etc.)

**L'IA est autoris√©e** pour :

* Comprendre des concepts
* D√©bloquer sur des erreurs
* G√©n√©rer des configurations de base
* Apprendre de nouvelles syntaxes

[WARNING]
====
**MAIS ATTENTION AU PLAGIAT !**

Nous reconnaissons facilement :

* Le code g√©n√©r√© par IA (style, commentaires, structure)
* Les explications copi√©es-coll√©es sans compr√©hension
* Les configurations "par d√©faut" non adapt√©es √† votre cas

**L'IA doit vous aider √† APPRENDRE, pas √† √âVITER DE R√âFL√âCHIR.**
====

**Bonne utilisation de l'IA :**

[source]
----
Prompt : "Explique-moi comment fonctionne un health check Docker Compose"
‚Üí Lire la r√©ponse, comprendre, adapter √† votre cas
‚Üí Tester, documenter ce que vous avez compris
----

**Mauvaise utilisation de l'IA :**

[source]
----
Prompt : "G√©n√®re-moi un docker-compose.yml complet pour l'examen"
‚Üí Copier-coller sans comprendre
‚Üí √áa ne marche pas, vous ne savez pas pourquoi
‚Üí Vous ne pouvez pas expliquer vos choix
----

=== Erreurs courantes √† √©viter

[cols="2,3", options="header"]
|===
|Erreur |Solution

|‚ùå Secrets dans Git (`.env` committ√©)
|‚úÖ Ajouter `.env` au `.gitignore`, committer `.env.example`

|‚ùå Images trop grosses (> 1 Go)
|‚úÖ Multi-stage builds, images Alpine, `.dockerignore`

|‚ùå Pas de health checks
|‚úÖ Ajouter `healthcheck` sur tous les services

|‚ùå Volumes anonymes
|‚úÖ Utiliser des volumes **nomm√©s** (section `volumes:`)

|‚ùå Tout en `root`
|‚úÖ Cr√©er un utilisateur non-root dans les Dockerfiles

|‚ùå Documentation absente
|‚úÖ Documenter au fur et √† mesure, pas √† la fin

|‚ùå Commits directs sur `main`
|‚úÖ Utiliser des branches et des Merge Requests

|‚ùå Configurations en dur (localhost, ports)
|‚úÖ Utiliser des variables d'environnement

|‚ùå Logs perdus (sortie standard uniquement)
|‚úÖ Int√©gration avec Logstash/Kibana

|‚ùå Pas de tests (Goss, load testing)
|‚úÖ Automatiser les tests dans la CI/CD
|===

== Ressources utiles

=== Documentation officielle

* **Docker** : https://docs.docker.com/
* **Docker Compose** : https://docs.docker.com/compose/
* **Docker Hub** (images) : https://hub.docker.com/
* **Nginx** : https://nginx.org/en/docs/
* **Apache HTTPd** : https://httpd.apache.org/docs/
* **Tomcat** : https://tomcat.apache.org/
* **PostgreSQL** : https://www.postgresql.org/docs/
* **MySQL** : https://dev.mysql.com/doc/
* **Elasticsearch** : https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html
* **Logstash** : https://www.elastic.co/guide/en/logstash/current/index.html
* **Kibana** : https://www.elastic.co/guide/en/kibana/current/index.html

=== Exemples et tutoriels

* **Awesome Compose** : https://github.com/docker/awesome-compose (exemples officiels)
* **Votre cours Docker** : Tout est dedans ! Relisez les chapitres :
** Docker Compose
** Images Docker
** Volumes
** R√©seaux
** S√©curit√© et Production

=== Outils

* **Trivy** (scanning) : https://github.com/aquasecurity/trivy
* **Goss** (testing) : https://github.com/goss-org/goss
* **Updatecli** (d√©pendances) : https://www.updatecli.io/
* **k6** (load testing) : https://k6.io/
* **Prometheus** : https://prometheus.io/
* **Grafana** : https://grafana.com/

== FAQ

**Q: Peut-on utiliser Docker Swarm au lieu de Docker Compose ?**

R: Non, l'objectif est d'utiliser Docker Compose. Docker Swarm est hors p√©rim√®tre pour ce projet.

---

**Q: Doit-on obligatoirement utiliser la stack ELK ? Peut-on utiliser Loki/Grafana √† la place ?**

R: La stack ELK est **obligatoire** pour la partie principale. Vous pouvez ajouter Loki/Grafana en compl√©ment valoris√© si vous le souhaitez.

---

**Q: Peut-on utiliser une application existante (Jenkins, Nexus, etc.) au lieu de cr√©er notre propre WAR ?**

R: Oui, tant que l'application :

* Est d√©ploy√©e comme un WAR sur votre serveur d'application
* Se connecte √† la base de donn√©es
* Est fonctionnelle et accessible

---

**Q: Les compl√©ments valoris√©s sont-ils obligatoires pour avoir 10/10 ?**

R: Non. Si vous obtenez 10/10 sur les crit√®res principaux, vous n'avez pas besoin de compl√©ments.

Les compl√©ments servent √† **compenser** les points manquants et √† d√©montrer des comp√©tences avanc√©es.

---

**Q: Peut-on faire plus de 10/10 sur la Partie 1 ?**

R: Non, la note est plafonn√©e √† 10/10.

---

**Q: Combien de compl√©ments faut-il faire ?**

R: Il n'y a pas de nombre impos√©. Privil√©giez la **qualit√©** :

* 1-2 compl√©ments **bien faits** > 4 compl√©ments **b√¢cl√©s**

---

**Q: Peut-on proposer un compl√©ment non list√© ?**

R: Oui, mais **demandez validation** via une issue GitLab avant de vous lancer. Proposez :

* Description du compl√©ment
* Valeur p√©dagogique
* Estimation du temps n√©cessaire

---

**Q: Les images Docker doivent-elles √™tre publi√©es sur Docker Hub ?**

R: Ce n'est pas obligatoire mais c'est un plus (bonne pratique professionnelle).

Si vous publiez vos images :

* Utilisez un registry public (Docker Hub, GHCR, etc.)
* Documentez les tags dans le README
* Ajoutez les URLs dans le `compose.yml`

---

**Q: Doit-on impl√©menter HTTPS avec certificat SSL/TLS ?**

R: Ce n'est pas obligatoire mais valoris√© (peut compenser des points manquants).

Si vous impl√©mentez HTTPS :

* Utilisez Let's Encrypt avec Caddy (le plus simple)
* Ou configurez Nginx avec des certificats auto-sign√©s
* Documentez la configuration dans le README

---

**Q: Peut-on travailler sur plusieurs branches en parall√®le ?**

R: Oui, c'est m√™me recommand√© ! Utilisez des branches pour :

* Chaque fonctionnalit√© (`feature/elk-stack`)
* Chaque compl√©ment (`feature/prometheus-grafana`)
* Chaque correction (`fix/nginx-config`)

---

**Q: Que faire si on est bloqu√© ?**

R: **Demandez de l'aide !** Via :

* Issue GitLab (pour les questions techniques)
* Merge Request (pour une review interm√©diaire)
* Email (en dernier recours)

Ne restez pas bloqu√© 2 jours sur un probl√®me, demandez apr√®s 1-2 heures de recherche.

---

**Q: La date limite (4 janvier 2026) inclut-elle les heures ?**

R: Oui, la deadline est **4 janvier 2026 √† 23h59** (minuit).

Tous les commits apr√®s cette heure seront ignor√©s.

[TIP]
====
**Astuce :** Ne vous y prenez pas au dernier moment ! Visez le **31 d√©cembre** pour terminer, cela vous laisse une marge.
====

---

**Q: Peut-on modifier le projet apr√®s la deadline pour corriger des bugs ?**

R: Non. Seuls les commits **avant** le 4 janvier 2026 √† 23h59 seront √©valu√©s.

== Conclusion

Ce projet est une opportunit√© de **mettre en pratique** tout ce que vous avez appris dans ce cours et de vous **pr√©parer** aux pratiques DevOps professionnelles.

**Nos attentes :**

* Une architecture **fonctionnelle** et **bien con√ßue**
* Une documentation **compl√®te** et **professionnelle**
* Des choix techniques **justifi√©s**
* Une communication **active** (MR, Issues)
* Du **travail d'√©quipe** (bin√¥me)

[IMPORTANT]
====
**Rappel de notre philosophie :**

L'objectif est de vous **pr√©parer** √† l'entreprise, pas de vous **pi√©ger** !

* Posez des questions
* Demandez des clarifications
* Sollicitez des reviews interm√©diaires
* Communiquez via GitLab

**Nous sommes l√† pour vous aider √† r√©ussir !**
====

**Bon courage et amusez-vous bien !** üöÄ

---

**Contact :**

* Bruno Verachten : gounthar@gmail.com
* GitLab : @gounthar

**Ressources :**

* Repository du cours : https://github.com/gounthar/cours-devops-docker
* Slides du cours : https://gounthar.github.io/cours-devops-docker/
