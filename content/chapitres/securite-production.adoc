[background-color="Navy"]
= S√©curit√© et Production Docker

image::security-production-header.png[height=400px]

[.notes]
--
Dur√©e totale : 3 heures
Session pratique avec projet fil rouge SecureVote
--

== Objectifs de la session

[%step]
* Comprendre et appliquer les bonnes pratiques de s√©curit√© Docker
* Optimiser les conteneurs pour la production
* G√©rer les registres d'images Docker
* D√©ployer une application s√©curis√©e et production-ready

[.notes]
--
Cette session est enti√®rement bas√©e sur un projet fil rouge : SecureVote
Les √©tudiants partent d'une version fonctionnelle mais dangereuse
Ils la transforment progressivement en d√©ploiement production-ready
--

[background-color="MediumBlue"]
== Projet Fil Rouge : SecureVote

SecureVote : Une application de vote en ligne moderne

[%step]
* Frontend React (interface de vote)
* Backend API Python Flask
* Base de donn√©es PostgreSQL
* Redis pour le cache
* Nginx comme reverse proxy

**D√©p√¥t GitHub :** https://github.com/gounthar/securevote

[.notes]
--
Cette application repr√©sente un cas d'usage r√©aliste : une stack web compl√®te typique des applications modernes.
L'aspect "vote" rend le projet concret et engageant.
Les √©tudiants vont manipuler 5 technologies diff√©rentes, ce qui refl√®te la r√©alit√© du DevOps.
Insister sur le fait que c'est LEUR projet pour les 3 heures : ils vont le faire √©voluer eux-m√™mes.

**STACK TECHNIQUE EXPLIQU√âE :**

‚Ä¢ **Flask (Python)** : Framework web l√©ger pour API REST. Alternative √† Django (plus lourd), Express.js (Node), ou Spring (Java).
  - Tr√®s utilis√© pour des APIs rapides et microservices
  - Langage : Python (facile √† lire m√™me sans le conna√Ætre)
  - Port : 5000 par d√©faut
  - R√¥le ici : G√®re les requ√™tes HTTP (GET /votes, POST /vote), connexion DB, logique m√©tier

‚Ä¢ **React (JavaScript)** : Biblioth√®que JavaScript pour interfaces utilisateur (pas un framework complet comme Angular ou Vue).
  - D√©velopp√© par Facebook, tr√®s populaire (Netflix, Airbnb, etc.)
  - Langage : JavaScript/JSX
  - Port : 3000 en d√©veloppement (webpack dev server)
  - R√¥le ici : Affiche l'interface de vote, boutons, r√©sultats en temps r√©el

‚Ä¢ **PostgreSQL** : Base de donn√©es relationnelle robuste (alternative open-source √† Oracle, MySQL).
  - Stockage persistant des donn√©es
  - Port : 5432 par d√©faut
  - R√¥le ici : Stocke les votes, les options de vote, les r√©sultats

‚Ä¢ **Redis** : Base de donn√©es en m√©moire ultra-rapide, utilis√©e comme cache.
  - Prononc√© "RED-iss" (Remote Dictionary Server)
  - Port : 6379 par d√©faut
  - R√¥le ici : Cache les r√©sultats de vote pour √©viter de requ√™ter PostgreSQL √† chaque fois (performance !)

‚Ä¢ **Nginx** : Serveur web et reverse proxy tr√®s performant (concurrent d'Apache).
  - Prononc√© "engine-x"
  - Port : 80 (HTTP) / 443 (HTTPS)
  - R√¥le ici : Point d'entr√©e unique, route les requ√™tes vers frontend (/) ou backend (/api)

**POURQUOI CETTE STACK ?** C'est une architecture moderne typique : frontend SPA (Single Page App) + API REST + DB + cache + reverse proxy.
On la retrouve chez des entreprises comme Uber, Spotify, Instagram (avec des variations).
--

== Architecture de l'application

[source,yaml]
----
services:
  frontend:    # React app
  backend:     # Flask API
  database:    # PostgreSQL
  cache:       # Redis
  proxy:       # Nginx
----

Architecture multi-tiers classique pour DevOps

[.notes]
--
Architecture en 5 services : c'est suffisamment complexe pour √™tre int√©ressant, mais pas trop pour 3h.
Proxy en point d'entr√©e unique : seul port expos√© en prod, pattern essentiel √† comprendre.
Cache Redis : montre l'importance de la performance en production.
Cette architecture se retrouve dans 80% des applications web modernes.

**COMMENT LES COMPOSANTS COMMUNIQUENT :**

1. **Utilisateur ‚Üí Nginx (port 8080)** : L'utilisateur acc√®de √† http://localhost:8080
   - Nginx re√ßoit TOUTES les requ√™tes (le "portier" de l'application)

2. **Nginx ‚Üí Frontend (port 3000)** : Pour les pages web (/, /index.html, /static/...)
   - Nginx fait du "proxy_pass" : il redirige la requ√™te vers React
   - React retourne du HTML/CSS/JavaScript

3. **Nginx ‚Üí Backend (port 5000)** : Pour les requ√™tes API (/api/...)
   - Exemple : POST /api/vote ‚Üí Nginx redirige vers Flask
   - Flask traite la logique et retourne du JSON

4. **Backend ‚Üí Database (port 5432)** : Flask se connecte √† PostgreSQL
   - Utilise le driver psycopg2 (biblioth√®que Python pour PostgreSQL)
   - Exemples : INSERT INTO votes, SELECT COUNT(*) FROM votes

5. **Backend ‚Üí Cache (port 6379)** : Flask interroge Redis en premier
   - Si donn√©e en cache ‚Üí retour imm√©diat (rapide !)
   - Si pas en cache ‚Üí requ√™te PostgreSQL + mise en cache pour la prochaine fois

**AVANTAGES DE CETTE ARCHITECTURE :**
- **S√©paration des responsabilit√©s** : chaque service a un r√¥le clair
- **Scalabilit√©** : on peut dupliquer frontend/backend ind√©pendamment
- **S√©curit√©** : seul Nginx est expos√©, les autres services sont internes
- **Performance** : Redis √©vite de surcharger PostgreSQL

**EN PHASE 1** : Tous les ports sont expos√©s (5432, 6379, 5000, 3000, 8080) = VULN√âRABILIT√â !
**EN PHASE 2/3** : Seul le port 8080 (Nginx) est expos√©, le reste est interne.
--

== Votre mission

[%step]
* **Phase 1** (30 min) : D√©marrer l'application "dangereuse"
* **Phase 2** (1h15) : S√©curiser l'application
* **Phase 3** (1h) : Optimiser pour la production

[%step]
WARNING: L'application initiale contient de nombreuses vuln√©rabilit√©s volontaires !

[background-color="DarkRed"]
== Phase 1 : D√©couverte (30 min)

[source,bash]
----
git clone https://github.com/gounthar/securevote.git
cd securevote/phase1
docker compose up -d

# V√©rifier l'√©tat des services
docker compose ps

# Suivre les logs (Ctrl+C pour quitter)
docker compose logs -f
----

[%step]
* **Attendre** que tous les services soient UP (~30 secondes)
* Acc√©dez √† http://localhost:8080
* Testez l'application de vote

[.notes]
--
Phase cruciale : les √©tudiants doivent D√âCOUVRIR eux-m√™mes les vuln√©rabilit√©s.
IMPORTANT : Backend peut prendre 10-20s √† d√©marrer ‚Üí nginx red√©marre automatiquement apr√®s.
Si "host not found in upstream" dans logs nginx : c'est NORMAL, attendre 30s.
Ne pas leur donner les r√©ponses tout de suite - les laisser chercher 5-10 minutes.
L'application FONCTIONNE : c'est volontaire, montrer qu'une app vuln√©rable peut sembler normale.
Circuler entre les groupes : certains vont paniquer si nginx red√©marre.
--

== Analyse des vuln√©rabilit√©s

Explorez les fichiers et identifiez les probl√®mes :

[%step]
* Qui ex√©cute les conteneurs ?
* O√π sont stock√©s les secrets ?
* Les images sont-elles √† jour ?
* Y a-t-il des ports expos√©s inutilement ?

== Points d'attention

**√Ä v√©rifier :**

[%step]
* `docker compose ps`
* `docker inspect <container>`
* Contenu des Dockerfile
* Variables d'environnement

[%step]
**Questions :** Quels risques identifiez-vous ? Comment exploiter ces failles ?

[background-color="OrangeRed"]
== S√©curit√© Docker : Les fondamentaux

Les 3 piliers de la s√©curit√© Docker :

[%step]
. **Images s√ªres** : Bases fiables, sans vuln√©rabilit√©s
. **Runtime s√©curis√©** : Isolation, utilisateurs non-root
. **Secrets prot√©g√©s** : Pas de mots de passe en clair

[.notes]
--
Framework simple pour m√©moriser : 3 piliers = 3 zones d'intervention.
Images = la BASE, si elle est pourrie, tout le reste est compromis.
Runtime = pendant l'ex√©cution, principe du moindre privil√®ge.
Secrets = la donn√©e la plus sensible, jamais en clair.
Cette structure va guider toute la Phase 2.
--

== Principe du moindre privil√®ge

[quote]
____
Un conteneur ne devrait avoir QUE les permissions n√©cessaires √† son fonctionnement
____

[%step]
* Pas d'ex√©cution en tant que root
* Capacit√©s Linux minimales
* Syst√®me de fichiers en lecture seule quand possible
* R√©seau isol√©

== Scan de vuln√©rabilit√©s

Les images Docker peuvent contenir des vuln√©rabilit√©s connues (CVE)

**Outils de scan :**

[%step]
* Docker Scout (int√©gr√© √† Docker Desktop)
* Trivy (open source, tr√®s populaire)
* Snyk, Grype

== Docker Scout en action

[source,bash]
----
# Scanner une image locale
docker scout cves python:3.11

# Comparer deux images
docker scout compare python:3.11 --to python:3.11-slim
----

TIP: D√©monstration live recommand√©e

[.notes]
--
D√âMONSTRATION LIVE ESSENTIELLE ici ! Les √©tudiants doivent VOIR les CVE en temps r√©el.
Comparer python:3.11 vs python:3.11-slim : diff√©rence spectaculaire (150+ CVE vs 20-30).
Si Docker Scout ne fonctionne pas, basculer sur Trivy : "docker run aquasec/trivy image python:3.11"
Montrer que le scan prend 10-30 secondes : c'est acceptable pour un pipeline CI/CD.
Insister : ce n'est pas parano√Øaque, c'est STANDARD en 2025.
--

== Installation de Trivy

**M√©thode rapide (pour le TP) :**

[source,bash]
----
# Installation directe du binaire
curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sudo sh -s -- -b /usr/local/bin
trivy --version
----

WARNING: `curl | sudo sh` est pratique MAIS dangereux en production !

**M√©thode s√©curis√©e (recommand√©e) :**

[source,bash]
----
# 1. T√©l√©charger le script
curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh -o /tmp/trivy-install.sh

# 2. Inspecter le contenu
less /tmp/trivy-install.sh

# 3. Ex√©cuter apr√®s v√©rification
sudo sh /tmp/trivy-install.sh -b /usr/local/bin
----

[.notes]
--
**IMPORTANT - PRATIQUE vs S√âCURIT√â :**

Dans un chapitre s√©curit√©, il est crucial de montrer LES DEUX approches :

**M√©thode rapide (curl | sudo sh) :**
- ‚úÖ Pratique pour le TP (gain de temps)
- ‚úÖ Recommand√©e par la doc officielle Trivy
- ‚ùå DANGEREUX : ex√©cute du code non v√©rifi√© en root
- ‚ùå Attaque potentielle : script modifi√© = compromission totale

**M√©thode s√©curis√©e (t√©l√©charger ‚Üí inspecter ‚Üí ex√©cuter) :**
- ‚úÖ Permet de v√©rifier le contenu avant ex√©cution
- ‚úÖ Bonne pratique s√©curit√© (principe de pr√©caution)
- ‚ùå Plus long (3 √©tapes au lieu d'1)

**POUR LE TP :**
- D√©monstration : montrer les DEUX approches
- Insister : "Je fais rapide pour le TP, MAIS en production..."
- Exercice p√©dagogique : comparer les deux = enseignement du compromis pratique/s√©curit√©

**MESSAGE CL√â :**
"En s√©curit√©, il y a souvent un compromis entre praticit√© et s√©curit√©.
Pour un TP p√©dagogique, curl|sh est OK. En production sur serveur critique, TOUJOURS inspecter avant."

Fonctionne sur toutes les distributions : Debian (y compris Trixie), Ubuntu, RHEL, etc.
Sur Debian Trixie/Testing : c'est LA m√©thode √† utiliser (le repo apt ne supporte pas encore trixie).

**PRODUCTION - VERSION PINNING ET INT√âGRIT√â :**

Pour une s√©curit√© maximale en production, deux am√©liorations essentielles :

1. **Version pinning** : Pin une version sp√©cifique au lieu de "latest"
   - √âvite les breaking changes inattendus
   - Le script d'installation supporte la s√©lection de release
   - Exemple : `curl -sfL ... | sudo sh -s -- -b /usr/local/bin v0.54.0`

2. **V√©rification d'int√©grit√©** : Checksum ou signature avant ex√©cution
   - T√©l√©charger le checksum depuis GitHub releases
   - V√©rifier avec `sha256sum --check`
   - Garantit que le binaire n'a pas √©t√© alt√©r√©

Ces √©tapes sont omises dans le TP pour simplicit√©, mais OBLIGATOIRES en production CI/CD.
--

== Installation Trivy : Alternatives

**Si vous n'avez pas les droits sudo :**

[source,bash]
----
# Via Docker (aucune installation n√©cessaire)
docker run --rm \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -v $HOME/.cache/trivy:/root/.cache \
  aquasec/trivy:0.54.1 image python:3.11
----

TIP: Pin la version (`:0.54.1`) et persist le cache (`-v $HOME/.cache`) pour performances

**Autres syst√®mes :**

[%step]
* **macOS :** `brew install trivy`
* **Debian/Ubuntu stable :** Via apt (voir documentation)

[.notes]
--
**M√âTHODE DOCKER :**
- Aucune installation n√©cessaire
- Garantit que tout le monde a la m√™me version
- Peut √™tre plus lent la premi√®re fois (t√©l√©charge l'image)
- Syntaxe un peu plus longue

**CHOIX POUR LE TP :**
- D√©monstration enseignant : script d'installation (rapide, propre)
- √âtudiants : script d'installation OU Docker selon permissions
- Premi√®re utilisation : le scan sera lent (~30s) car t√©l√©charge la base CVE (~200 Mo)
- Mise √† jour de la base : `trivy image --download-db-only`

**TROUBLESHOOTING :**
- Permission denied ‚Üí Ajouter sudo ou utiliser m√©thode Docker
- Erreur "trixie Release not found" (si tentative apt) ‚Üí Utiliser le script
--

== Exemple de r√©sultat Trivy

[source,bash]
----
trivy image python:3.11

Total: 145 vulnerabilities (52 HIGH, 93 MEDIUM)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Library  ‚îÇ Vulnerability‚îÇ Severity ‚îÇ Version ‚îÇ
‚îÇ openssl  ‚îÇ CVE-2023-XXX ‚îÇ HIGH     ‚îÇ 1.1.1n  ‚îÇ
‚îÇ curl     ‚îÇ CVE-2023-YYY ‚îÇ MEDIUM   ‚îÇ 7.68.0  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
----

[%step]
**Action :** Mettre √† jour, changer d'image de base, appliquer des patches

== Utilisateurs non-root

**Probl√®me :** Par d√©faut, les processus s'ex√©cutent en tant que root

[source,dockerfile]
----
FROM python:3.11
COPY app.py /app/
CMD ["python", "/app/app.py"]  # Root !
----

WARNING: Si compromis, l'attaquant a les privil√®ges root !

[.notes]
--
Erreur N¬∞1 des d√©butants Docker : tout tourne en root par d√©faut.
Analogie : c'est comme lancer toutes vos apps Windows en "Administrateur" en permanence.
Si un attaquant exploite une faille dans votre app Python, il a root sur le conteneur.
Avec root, il peut : installer des outils, scanner le r√©seau, pivoter vers d'autres conteneurs.
Montrer docker exec <container> whoami ‚Üí retourne "root" = MAUVAIS !
--

== Solution : Utilisateur d√©di√©

[source,dockerfile]
----
FROM python:3.11-slim

RUN groupadd -r appuser && useradd -r -g appuser appuser
WORKDIR /app
COPY app.py /app/
RUN chown -R appuser:appuser /app

USER appuser
CMD ["python", "/app/app.py"]
----

== Bonnes pratiques utilisateur

[%step]
* Toujours cr√©er un utilisateur d√©di√©
* UID > 1000 (√©viter conflits syst√®me)
* Ne jamais revenir √† root apr√®s USER
* V√©rifier : `docker exec <container> whoami`

== Comprendre les UID Linux

Linux num√©rote les utilisateurs (User ID) :

[%step]
* **UID 0** : root (super-utilisateur)
* **UID 1-999** : comptes syst√®me (www-data, postgres, redis...)
* **UID ‚â• 1000** : utilisateurs normaux et applications

[%step]
WARNING: Avec volumes mont√©s, UID < 1000 peut cr√©er des conflits de s√©curit√© !

[.notes]
--
**POURQUOI C'EST IMPORTANT :**

Si vous cr√©ez un utilisateur avec UID 33 (www-data) dans votre conteneur,
et que l'h√¥te a AUSSI www-data (UID 33), le conteneur pourra acc√©der aux fichiers
de www-data sur l'H√îTE via les volumes mont√©s = faille de s√©curit√© !

**BONNE PRATIQUE :**
- Sans volumes mont√©s : `useradd -r` acceptable (cr√©e UID syst√®me < 1000)
- Avec volumes mont√©s : `useradd -u 1001` ou laisser le syst√®me choisir (‚â• 1000)

Dans SecureVote, `-r` est acceptable car pas de volumes mont√©s critiques avec l'h√¥te.
--

== UID : Exemple pratique

[source,dockerfile]
----
# RISQU√â : UID fixe < 1000
RUN useradd -u 33 appuser
# Conflit possible si l'h√¥te a www-data (UID 33) !

# S√õR : UID > 1000
RUN useradd -u 1001 appuser

# OU laisser le syst√®me choisir (sera ‚â• 1000)
RUN useradd appuser
----

[%step]
V√©rifier : `docker exec <container> id appuser`

[.notes]
--
Montrer la commande `id` dans un conteneur pour voir l'UID assign√©.
Exemple de r√©sultat : uid=1001(appuser) gid=1001(appuser) groups=1001(appuser)

Pour les √©tudiants : expliquer que c'est comme les num√©ros de t√©l√©phone -
il faut √©viter que deux personnes aient le m√™me num√©ro !

L'option `-r` dans `useradd -r` cr√©e un "system user" avec UID < 1000.
C'est historique : les services syst√®me (Apache, Nginx, PostgreSQL) utilisent des UID bas.

**PRODUCTION - USER NUM√âRIQUE POUR PORTABILIT√â :**

Pour maximiser la portabilit√© entre diff√©rentes images de base :
- Pr√©f√©rer `USER 1001:1001` au lieu de `USER appuser`
- √âvite les lookups de noms d'utilisateurs qui peuvent √©chouer
- Garantit coh√©rence m√™me si `/etc/passwd` diff√®re entre images
- Crucial avec volumes mont√©s partag√©s entre plusieurs conteneurs

Exemple robuste :
```dockerfile
RUN groupadd -g 1001 appgroup && useradd -u 1001 -g 1001 appuser
USER 1001:1001
```

Cette approche num√©rique est LA meilleure pratique pour production/Kubernetes.
--

== Gestion des secrets

**Mauvaise pratique :**

[source,yaml]
----
environment:
  - POSTGRES_PASSWORD=super_secret_123  # NON !
----

WARNING: Visible dans `docker inspect`, logs, historique !

[.notes]
--
Pi√®ge classique : secrets en clair dans docker-compose.yml = COMMIT√âS sur Git = PUBLICS.
Anecdote : chercher "removed password" sur GitHub = des millions de r√©sultats.
Les secrets restent dans l'historique Git m√™me apr√®s suppression !
docker inspect montre TOUTES les variables d'env = un attaquant peut lire.
Les logs peuvent accidentellement afficher les secrets lors du d√©marrage.
Message cl√© : les secrets ne doivent JAMAIS √™tre versionn√©s.
--

== Bonne pratique : Fichiers .env

**√âtape 1 : Cr√©er le fichier .env**

[source,bash]
----
# .env (√† ne JAMAIS commiter)
DB_PASSWORD=super_secret_123
----

**√âtape 2 : Prot√©ger avec .gitignore**

[source,bash]
----
# .gitignore
.env
secrets/
----

**√âtape 3 : Utiliser dans docker-compose.yml**

[source,yaml]
----
environment:
  POSTGRES_PASSWORD: ${DB_PASSWORD}
  API_KEY: ${API_KEY:-default_key}     # Valeur par d√©faut si absent
  DB_HOST: ${DB_HOST?required}          # Erreur si non d√©fini
----

TIP: Docker Compose charge automatiquement le fichier .env

**Syntaxes avanc√©es :**

[%step]
* `${VAR:-default}` : Utilise `default` si VAR n'est pas d√©finie
* `${VAR?error message}` : √âchoue avec message si VAR manquante
* Utile pour s√©parer config obligatoire vs optionnelle

== Alternative 1 : Docker Secrets

**Gestion native dans Docker Swarm**

[%step]
* Secrets crypt√©s dans le cluster Swarm
* Mont√©s en RAM dans `/run/secrets/`
* Acc√®s contr√¥l√© par service

[source,bash]
----
echo "secret123" | docker secret create db_password -
docker service create --secret db_password postgres
----

[.notes]
--
**DOCKER SECRETS - GUIDE D√âTAILL√â**

Qu'est-ce que c'est ?
- Syst√®me de gestion de secrets int√©gr√© √† Docker Swarm (orchestrateur Docker natif)
- Secrets stock√©s crypt√©s dans le cluster Swarm
- Mont√©s comme fichiers dans /run/secrets/ (en RAM, jamais sur disque)
- Les secrets ne transitent JAMAIS sur le disque dur, toujours en m√©moire

**Avantages :**
‚úÖ Natif Docker, pas de service externe √† installer
‚úÖ Crypt√© au repos et en transit (TLS mutuel entre n≈ìuds)
‚úÖ Acc√®s contr√¥l√© par service (seuls les services autoris√©s peuvent lire)
‚úÖ Rotation possible (cr√©er nouveau secret, red√©ployer service)
‚úÖ Gratuit, inclus dans Docker

**Inconv√©nients :**
‚ùå N√©cessite Docker Swarm (pas Compose standalone ou Kubernetes)
‚ùå Moins de fonctionnalit√©s que Vault (pas de rotation automatique, audit limit√©)
‚ùå Courbe d'apprentissage Swarm si vous utilisez Compose

**Comment √ßa fonctionne :**
1. Cr√©er le secret : `docker secret create db_password secret.txt`
2. Attribuer au service : `docker service create --secret db_password myapp`
3. Application lit `/run/secrets/db_password` (fichier en RAM)

**Quand l'utiliser :**
- Environnements Docker Swarm en production
- Petites/moyennes infrastructures (5-50 conteneurs)
- Alternative simple √† Vault pour d√©buter
- Besoin de secrets crypt√©s sans infrastructure externe

**Pour SecureVote :**
Non utilis√© dans le TP (on reste sur Compose), mais √©volution possible si migration vers Swarm.
--

== Alternative 2 : HashiCorp Vault

**Solution d'entreprise pour secrets**

[%step]
* Serveur centralis√© avec API REST
* Rotation automatique des credentials
* Audit complet et secrets dynamiques

[source,bash]
----
# Application interroge Vault via API
vault kv get -field=password secret/database/prod
----

[%step]
WARNING: N√©cessite infrastructure d√©di√©e (serveur Vault)

[.notes]
--
**VAULT - SOLUTION ENTERPRISE**

Qu'est-ce que c'est ?
- Solution d'entreprise d√©di√©e √† la gestion de secrets (HashiCorp)
- Serveur centralis√© de secrets avec API REST
- Audit complet, rotation automatique, dur√©e de vie des secrets
- "Fort Knox" des secrets : le standard de l'industrie

**Avantages :**
‚úÖ Solution la plus compl√®te du march√©
‚úÖ Rotation automatique des secrets (DB credentials, API keys, certificats)
‚úÖ Audit trail complet (qui a acc√©d√© √† quoi, quand, depuis o√π)
‚úÖ Secrets dynamiques (g√©n√®re des credentials temporaires √† la demande)
‚úÖ Int√©gration avec cloud providers (AWS, Azure, GCP)
‚úÖ Fonctionne avec Docker Compose, Swarm, Kubernetes, VMs
‚úÖ Versioning des secrets (rollback possible)
‚úÖ Policies granulaires (contr√¥le d'acc√®s fin)

**Inconv√©nients :**
‚ùå Infrastructure suppl√©mentaire √† g√©rer (serveur Vault √† maintenir, haute dispo)
‚ùå Courbe d'apprentissage √©lev√©e (concepts : policies, auth methods, engines)
‚ùå Co√ªt version enterprise pour features avanc√©es (namespaces, r√©plication)
‚ùå Complexit√© op√©rationnelle (unsealing, backup, disaster recovery)

**Exemple concret :**

[source,bash]
----
# Vault g√©n√®re des credentials MySQL temporaires (valides 1h)
vault read database/creds/myapp
# Key            Value
# lease_id       database/creds/myapp/abcd1234
# username       v-myapp-abc123
# password       A1b2C3d4...
----

**Quand l'utiliser :**
- Grandes organisations avec 100+ secrets √† g√©rer
- Exigences de compliance strictes (SOC2, ISO27001, PCI-DSS)
- Multi-cloud ou infrastructure hybride (secrets partag√©s)
- Besoin de secrets dynamiques (ex: credentials DB temporaires pour chaque d√©ploiement)
- √âquipe d√©di√©e √† la s√©curit√©/infrastructure

**Co√ªt/Ressources :**
- Open source : gratuit mais features limit√©es
- Enterprise : $$$ (√† partir de 15k$/an pour petite org)
- N√©cessite : 1-2 personnes d√©di√©es pour l'op√©rationnel

**Pour SecureVote :**
Overkill pour le TP. Mentionner comme √©volution si l'application devient un service SaaS avec 1000+ clients.
--

== Alternative 3 : Cloud Providers

**Services manag√©s AWS / Azure / GCP**

[%step]
* **AWS Secrets Manager** : int√©gration RDS/Aurora
* **Azure Key Vault** : int√©gration Azure AD, HSM
* **GCP Secret Manager** : int√©gration Cloud Run/GKE

[%step]
‚úÖ Enti√®rement manag√©, haute disponibilit√©
‚ùå Vendor lock-in, co√ªt √† l'usage

[.notes]
--
**CLOUD PROVIDERS - SERVICES MANAG√âS**

Qu'est-ce que c'est ?
- Services manag√©s de gestion de secrets par les cloud providers
- Int√©gration native avec les autres services du cloud
- Z√©ro maintenance, facturation √† l'usage

**Les 3 grands providers :**

**1. AWS Secrets Manager**
- Rotation automatique pour RDS, Aurora, Redshift, DocumentDB
- Int√©gration native avec Lambda, ECS, EC2 via IAM roles
- Versioning automatique des secrets
- Co√ªt : ~0.40$/secret/mois + 0.05$/10k requ√™tes

**2. Azure Key Vault**
- Int√©gration avec Azure AD pour l'authentification
- HSM hardware optionnel (cl√©s stock√©es dans modules cryptographiques certifi√©s)
- Managed identities pour AKS, App Service, Functions
- Co√ªt : ~0.03$/secret/mois + 0.03$/10k op√©rations

**3. GCP Secret Manager**
- Int√©gration native avec Cloud Run, GKE, Cloud Functions
- R√©plication multi-r√©gion automatique
- Audit via Cloud Logging
- Co√ªt : ~0.06$/secret/mois + 0.03$/10k acc√®s

**Avantages :**
‚úÖ Enti√®rement manag√© (pas de serveur √† maintenir, pas de patching)
‚úÖ Int√©gration native avec services cloud (IAM, load balancers, etc.)
‚úÖ Rotation automatique pour certains services (RDS sur AWS, etc.)
‚úÖ Haute disponibilit√© garantie par le provider (SLA 99.9%+)
‚úÖ Audit via CloudTrail / Azure Monitor / Cloud Logging
‚úÖ Facile √† d√©marrer (quelques clics dans la console)

**Inconv√©nients :**
‚ùå Vendor lock-in (difficile de migrer vers autre cloud)
‚ùå Co√ªt √† l'usage (peut devenir cher avec 1000+ secrets)
‚ùå Moins flexible que Vault pour du multi-cloud
‚ùå Features variables selon provider (AWS plus complet que GCP)

**Comparaison des co√ªts (exemple 100 secrets, 1M requ√™tes/mois) :**
- AWS : ~40$ + 5$ = 45$/mois
- Azure : ~3$ + 3$ = 6$/mois
- GCP : ~6$ + 30$ = 36$/mois
- Vault self-hosted : ~200$/mois (serveur) + temps √©quipe

**Quand l'utiliser :**
- Infrastructure d√©j√† sur un cloud public (AWS, Azure, GCP)
- Pas d'√©quipe d√©di√©e pour g√©rer un Vault
- Budget pour services manag√©s
- Besoin d'int√©gration native avec services cloud
- Startup/PME qui veut se concentrer sur le produit, pas l'infra

**Pour SecureVote :**
Si d√©ploiement sur AWS/Azure/GCP ‚Üí excellent choix. Plus simple que Vault, pas de maintenance.
--

== Alternative 4 : Variables shell

**Passage direct via environnement**

[%step]
* Simple pour dev et CI/CD
* Secrets inject√©s au runtime

[source,bash]
----
# En une ligne
DB_PASSWORD="secret123" docker compose up -d

# Ou via export
export DB_PASSWORD="secret123"
docker compose up -d
----

[%step]
WARNING: Visible dans `ps aux` et historique shell !

[.notes]
--
**VARIABLES D'ENVIRONNEMENT SHELL**

Qu'est-ce que c'est ?
- Passer les secrets via variables d'environnement du shell au lancement
- Les secrets restent en m√©moire du processus shell
- M√©thode la plus simple, mais limitations importantes

**Avantages :**
‚úÖ Tr√®s simple, pas de fichier .env √† g√©rer
‚úÖ Secrets restent dans la session shell (pas versionn√©s)
‚úÖ Utile pour CI/CD (GitLab CI, GitHub Actions injectent des variables)
‚úÖ Pas de d√©pendance externe
‚úÖ Id√©al pour scripts one-shot

**Inconv√©nients :**
‚ùå Visible dans `ps aux` (autres utilisateurs de la machine peuvent voir)
‚ùå Reste dans l'historique shell (~/.bash_history) si export
‚ùå Moins pratique pour plusieurs secrets (commande tr√®s longue)
‚ùå Perd les secrets si session shell se ferme (pas persistant)
‚ùå Difficile √† g√©rer en √©quipe (chacun doit set ses variables)

**Exemples d'utilisation :**

[source,bash]
----
# M√©thode 1 : Inline (pr√©f√©rable)
DB_PASSWORD="secret123" REDIS_PASSWORD="abc456" docker compose up -d

# M√©thode 2 : Export (reste en m√©moire shell)
export DB_PASSWORD="secret123"
export REDIS_PASSWORD="abc456"
docker compose up -d

# M√©thode 3 : Depuis fichier non versionn√©
source ~/secrets.sh  # contient les exports
docker compose up -d

# M√©thode 4 : CI/CD (GitLab CI exemple)
# Les variables sont inject√©es par le runner
script:
  - docker compose up -d  # $DB_PASSWORD d√©j√† disponible
----

**Probl√®me de s√©curit√© - ps aux :**

[source,bash]
----
# Autre utilisateur peut voir :
ps aux | grep docker
# user  1234  ... docker compose up -d  # DB_PASSWORD=secret123 visible !
----

**Quand l'utiliser :**
- D√©veloppement local rapide (test ponctuel)
- CI/CD pipelines (GitLab CI, GitHub Actions, Jenkins)
  - Les secrets sont inject√©s par le syst√®me CI/CD
  - Ne restent pas dans l'historique du runner
- Scripts d'automatisation ponctuels
- Environnements √©ph√©m√®res (conteneurs CI qui sont d√©truits apr√®s)

**Quand NE PAS l'utiliser :**
- Production (trop risqu√©, pas d'audit)
- Serveurs partag√©s (autres users peuvent voir)
- Secrets critiques (passwords DB prod, API keys sensibles)

**Pour SecureVote :**
Acceptable pour tests locaux rapides. Mais pr√©f√©rer .env pour le TP (plus p√©dagogique, plus r√©aliste).
CI/CD bonus : montrer comment GitLab CI/GitHub Actions injectent les secrets.
--

== Comparaison des solutions

[cols="1,1,1,2", options="header"]
|===
|Solution |Complexit√© |Co√ªt |Cas d'usage

|Fichiers .env
|‚ö™ Faible
|üí∞ Gratuit
|Dev, petits projets

|Docker Secrets
|üü° Moyenne
|üí∞ Gratuit
|Docker Swarm prod

|Vault
|üî¥ √âlev√©e
|üí∞üí∞ Variable
|Grandes organisations

|Cloud Secrets
|üü° Moyenne
|üí∞üí∞ Payant
|D√©j√† sur cloud

|Variables shell
|‚ö™ Faible
|üí∞ Gratuit
|Dev local, CI/CD
|===

[.notes]
--
**GUIDE DE D√âCISION - Quelle solution choisir ?**

**Arbre de d√©cision simple :**

1. **Vous √™tes en d√©veloppement local ?**
   ‚Üí Fichiers .env (simple, rapide)

2. **Vous √™tes en production avec Docker Swarm ?**
   ‚Üí Docker Secrets (natif, crypt√©, gratuit)

3. **Vous √™tes sur AWS/Azure/GCP ?**
   ‚Üí Cloud Secrets Manager (manag√©, int√©gration native)

4. **Vous avez 100+ secrets, multi-cloud, compliance stricte ?**
   ‚Üí Vault (solution compl√®te mais complexe)

5. **Vous √™tes en CI/CD ?**
   ‚Üí Variables shell (inject√©es par le pipeline)

**√âvolution typique d'une startup :**

Phase 1 (MVP) : .env files
- Simple, rapide √† mettre en place
- OK pour 5-10 secrets

Phase 2 (Croissance) : Cloud Secrets Manager
- Migration vers AWS/Azure/GCP
- 20-50 secrets
- Besoin de rotation automatique pour RDS

Phase 3 (Scale-up) : Vault
- Multi-cloud (AWS + GCP)
- 100+ secrets
- √âquipe s√©curit√© d√©di√©e
- Compliance SOC2/ISO27001

**MESSAGE CL√â POUR LES √âTUDIANTS :**

"Commencez simple avec .env, mais pensez d√©j√† √† l'√©chelle.
Si vous rejoignez une entreprise avec 500 microservices, vous utiliserez Vault ou cloud secrets.
Le principe reste le m√™me : JAMAIS de secrets en clair dans Git !"

**POUR LE TP SECUREVOTE :**
- On utilise .env (p√©dagogique, simple)
- Discussion bonus : "Et si SecureVote devenait le prochain Doodle, avec 10M d'utilisateurs ?"
  ‚Üí Besoin de Vault ou AWS Secrets Manager
- Exercice bonus si temps : migrer vers Docker Secrets (Phase 3+)
--

[background-color="DarkOrange"]
== Phase 2 : S√©curisation (1h15)

Transformer SecureVote en application s√©curis√©e

[%step]
* Images s√ªres et l√©g√®res
* Scanner les vuln√©rabilit√©s avec Trivy
* Utilisateurs non-root
* Prot√©ger les secrets
* Isoler les r√©seaux

[.notes]
--
Phase la plus longue et la plus importante : 1h15 de pratique intensive.
Les √©tudiants doivent appliquer CONCR√àTEMENT tout ce qui vient d'√™tre vu.
Recommand√© : travail en bin√¥me pour favoriser l'entraide.
Circuler activement : c'est ici qu'ils vont bloquer.
Checkpoints r√©guliers toutes les 20-25 min pour synchroniser le groupe.
Objectif : phase1/ ne doit PLUS √™tre utilis√©e, tout le monde sur phase2/.
--

== Exercice 1 : Images s√©curis√©es (20 min)

**Mission :**

[%step]
. Scanner les images avec Docker Scout ou Trivy
. Identifier les vuln√©rabilit√©s critiques
. Remplacer par des images `-slim` ou `-alpine`
. Re-scanner et comparer

[source,bash]
----
docker scout cves securevote-backend:latest
# Modifier Dockerfile ‚Üí python:3.11-slim
docker compose build backend
docker scout cves securevote-backend:latest
----

[.notes]
--
Premier exercice : relativement simple pour mettre en confiance.
R√©sultat attendu : python:3.11 (150+ CVE) ‚Üí python:3.11-slim (20-30 CVE) = 80-90% de r√©duction.
Pour Node : node:20 ‚Üí node:20-alpine = encore plus spectaculaire.
Pi√®ge fr√©quent : oublier de rebuild apr√®s modification = image non scann√©e.
Attention : alpine peut casser certaines d√©pendances (musl vs glibc) ‚Üí pr√©f√©rer slim si probl√®me.
Montrer que le fichier phase2/INSTRUCTIONS.md contient des indices.
--

== Exercice 2 : Utilisateurs non-root (25 min)

**Mission :**

Modifier tous les Dockerfiles pour des utilisateurs non-root

[%step]
. Backend Python : cr√©er `flaskuser`
. Frontend React : cr√©er `reactuser`
. Nginx : utiliser `nginx-unprivileged`

[source,dockerfile]
----
FROM python:3.11-slim
RUN groupadd -r flaskuser && useradd -r -g flaskuser flaskuser
USER flaskuser
----

== V√©rification utilisateurs

[source,bash]
----
docker compose exec backend ps aux
# Le processus principal (PID 1) doit tourner en tant que flaskuser

docker compose exec frontend ps aux
# Le processus principal (PID 1) doit tourner en tant que reactuser
----

TIP: Si vous voyez UID 0 ou `root` pour le processus principal, c'est √† corriger !

== Exercice 3 : S√©curiser les secrets (30 min)

**Mission :**

[%step]
. Identifier les secrets en clair dans docker-compose.yml
. Cr√©er `.env` (sans le commiter !)
. Ajouter `.env` au `.gitignore`
. Utiliser les variables : `${DB_PASSWORD}`
. Cr√©er `.env.example` comme template

== Checkpoint Phase 2

V√©rification collective :

[%step]
* Scans : moins de vuln√©rabilit√©s ?
* Aucun conteneur en root ?
* Aucun secret en clair versionn√© ?
* Application fonctionne ?

[source,bash]
----
docker compose ps
docker compose exec backend ps aux
trivy image securevote-backend:latest --severity HIGH,CRITICAL
----

[background-color="DarkGreen"]
== Configuration Production

[.columns]
====
[.column]
--
**D√©veloppement :**

* Ressources illimit√©es
* Logs verbeux
* Red√©marrages manuels
--

[.column]
--
**Production :**

* Ressources limit√©es
* Logs structur√©s
* Auto-healing
--
====

[.notes]
--
Transition importante : Phase 2 = s√©curit√©, Phase 3 = production/fiabilit√©.
En dev : on se fiche des ressources, on veut du confort (logs d√©taill√©s, restart manuel).
En prod : on veut de la STABILIT√â, de la PR√âVISIBILIT√â, de l'AUTO-R√âPARATION.
Analogie : dev = voiture de test, prod = avion de ligne (syst√®mes redondants, monitoring constant).
Ces deux aspects (s√©curit√© + prod) sont compl√©mentaires et indissociables.
--

== Limites de ressources

**Pourquoi limiter ?**

[%step]
* Emp√™cher monopolisation du serveur
* Garantir stabilit√©
* Pr√©voir capacit√©
* D√©tecter fuites m√©moire

WARNING: Sans limites ‚Üí 100% CPU/RAM !

[.notes]
--
Histoire r√©elle : un conteneur mal configur√© monopolise 100% CPU d'un serveur = TOUS les autres services ralentissent.
Sans limites, Docker ne prot√®ge PAS : un conteneur peut tuer le serveur h√¥te.
Les limites permettent de PLANIFIER : "j'ai 16 Go, je peux faire tourner 10 conteneurs √† 1.5 Go chacun".
Les limites r√©v√®lent les fuites m√©moire : si votre app atteint syst√©matiquement la limite, elle fuit.
En prod, TOUJOURS d√©finir des limites. C'est comme les ceintures de s√©curit√© : obligatoire.
--

== D√©finir les limites

[source,yaml]
----
services:
  backend:
    deploy:
      resources:
        limits:
          cpus: '0.5'      # Max 50% CPU
          memory: 512M     # Max 512 Mo RAM
        reservations:
          cpus: '0.25'     # Min garanti
          memory: 256M
----

== Choisir les bonnes valeurs

[%step]
. D√©marrer sans limites
. Observer : `docker stats`
. Ajouter 20-30% de marge
. Tester sous charge
. Ajuster

== Politiques de red√©marrage

[source,yaml]
----
services:
  backend:
    restart: no              # Jamais
    restart: always          # Toujours
    restart: on-failure      # Si erreur
    restart: unless-stopped  # Sauf arr√™t manuel
----

[%step]
**Production :** Privil√©gier `unless-stopped` ou `on-failure`

== Restart avec limite

[source,yaml]
----
services:
  backend:
    restart: on-failure
----

NOTE: Pour limiter le nombre de tentatives en Docker Swarm, utilisez `deploy.restart_policy.max_attempts: 5`

√âvite les boucles infinies de red√©marrage

== Health checks

[source,yaml]
----
services:
  backend:
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
----

[.notes]
--
Health check = le contr√¥le a√©rien de vos conteneurs.
Un conteneur peut √™tre "running" mais MORT √† l'int√©rieur (app crash√©e, connexion DB perdue).
docker ps montre "Up" mais healthcheck montre "unhealthy" = probl√®me d√©tect√© !
Exemple concret : backend d√©marre en 5s, mais connexion DB prend 30s ‚Üí start_period: 40s.
interval: 30s = v√©rifier toutes les 30s, c'est raisonnable (pas trop fr√©quent, pas trop lent).
retries: 3 = tol√©rer 3 √©checs avant de marquer "unhealthy" = √©vite les faux positifs.
Le healthcheck doit √™tre RAPIDE (<1s) et L√âGER (pas de requ√™tes DB lourdes).
--

== Endpoint de sant√©

[source,python]
----
@app.route('/health')
def health():
    try:
        db.ping()
        return jsonify({"status": "healthy"}), 200
    except:
        return jsonify({"status": "unhealthy"}), 503
----

== D√©pendances entre services

[source,yaml]
----
services:
  backend:
    depends_on:
      database:
        condition: service_healthy
      cache:
        condition: service_started
----

[%step]
* `service_started` : D√©marr√© (pas forc√©ment pr√™t)
* `service_healthy` : Healthcheck valid√©
* `service_completed_successfully` : Termin√© avec succ√®s

== Monitoring et logs

**Observabilit√© :**

[%step]
* **Logs** : Que s'est-il pass√© ?
* **M√©triques** : Combien de CPU/RAM/requ√™tes ?
* **Traces** : Quel chemin a pris une requ√™te ?

TIP: TP13 a d√©j√† couvert ELK

== Driver de logs

[source,yaml]
----
services:
  backend:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"      # Max 10 Mo
        max-file: "3"        # Garder 3 fichiers
----

WARNING: Sans limites, les logs remplissent le disque !

== Logs structur√©s

**Mauvais :** `Server started on port 5000`

**Bon :**

[source,json]
----
{"timestamp":"2025-01-15T10:30:00Z","level":"INFO","service":"backend","message":"Server started","port":5000}
----

[%step]
Facilement parsables par ELK, Loki, etc.

[background-color="ForestGreen"]
== Phase 3 : Production (1h)

Optimiser SecureVote pour la production

[%step]
* Limites de ressources
* Politiques de red√©marrage
* Health checks
* Optimiser les logs
* Tester la r√©silience

[.notes]
--
Phase finale : transformation en app production-ready.
Les √©tudiants ont maintenant une app S√âCURIS√âE (Phase 2), ils vont la rendre FIABLE.
Cette phase inclut des TESTS de r√©silience : tuer des conteneurs, faire du load testing.
C'est ici qu'on voit si l'auto-healing fonctionne vraiment !
Les scripts load_test.sh et kill_test.sh sont fournis dans phase3/scripts/.
Encourager l'exp√©rimentation : "cassez votre app volontairement pour voir ce qui se passe".
Temps : 1h = 3 exercices de 15-25 min chacun + checkpoint final.
--

== Exercice 4 : Limites de ressources (20 min)

**Mission :**

[%step]
. Observer avec `docker stats`
. D√©finir limites appropri√©es
. Tester sous charge (script fourni)
. Ajuster

[source,bash]
----
docker stats --no-stream
./load_test.sh
docker stats
----

== Exercice 5 : Restart et Health (25 min)

**Mission :**

[%step]
. Ajouter politiques de red√©marrage
. Cr√©er endpoint `/health` dans backend
. Configurer healthchecks
. Tester en tuant un conteneur

[source,bash]
----
docker compose kill backend
docker compose ps
docker compose logs backend
----

== Exercice 6 : D√©pendances (15 min)

**Mission :**

[%step]
. Configurer `depends_on` avec conditions
. Tester ordre de d√©marrage
. Simuler indisponibilit√© DB
. V√©rifier backend ne d√©marre pas sans DB

== Checkpoint Phase 3

Application production-ready :

[%step]
* Limites de ressources ‚úÖ
* Auto-healing ‚úÖ
* Health checks ‚úÖ
* D√©pendances ordonn√©es ‚úÖ
* Logs optimis√©s ‚úÖ

[source,bash]
----
docker compose config --services
docker compose ps
docker stats --no-stream
----

[background-color="Navy"]
== Registres et Distribution

[%step]
* Serveur de stockage d'images Docker
* √âquivalent de npm pour Node, PyPI pour Python
* Public (Docker Hub) ou priv√© (self-hosted)
* Gestion des versions (tags)

== Docker Hub

[source,bash]
----
docker pull nginx:latest
# √âquivalent √† :
docker pull docker.io/library/nginx:latest
----

[%step]
* Gratuit pour images publiques
* Limites de rate (pull anonyme)

== Registres priv√©s

**Pourquoi ?**

[%step]
* Images propri√©taires
* Contr√¥le d'acc√®s
* Compliance et s√©curit√©
* Pas de limite de rate

== Solutions de registres

[%step]
* **Docker Registry** (open source)
* **Harbor** (CNCF, avec scan)
* **AWS ECR**, **Azure ACR**, **GCP GCR**
* **GitLab / GitHub Container Registry**

== D√©marrer un registre local

[source,bash]
----
docker run -d -p 5000:5000 --name registry registry:2
docker tag securevote-backend:latest localhost:5000/securevote-backend:latest
docker push localhost:5000/securevote-backend:latest
----

== Tags et versions

[source,bash]
----
# Bonne pratique : versionner
docker tag myapp:latest myregistry.com/myapp:1.2.3
docker tag myapp:latest myregistry.com/myapp:1.2
docker tag myapp:latest myregistry.com/myapp:latest
----

TIP: Plusieurs tags ‚Üí m√™me image

== Exercice 7 : Registre local (Bonus)

**Si le temps le permet :**

[%step]
. D√©marrer registre local (port 5000)
. Tagger images SecureVote
. Pousser vers registre
. Modifier docker-compose.yml
. Re-d√©ployer

[background-color="MediumBlue"]
== R√©capitulatif et bonnes pratiques

== Checklist s√©curit√©

[%step]
* ‚úÖ Images officielles et √† jour
* ‚úÖ Scan r√©gulier des vuln√©rabilit√©s
* ‚úÖ Utilisateurs non-root syst√©matiques
* ‚úÖ Secrets jamais en clair
* ‚úÖ R√©seau isol√© par d√©faut

== Checklist production

[%step]
* ‚úÖ Limites de ressources CPU/RAM
* ‚úÖ Politiques de red√©marrage
* ‚úÖ Health checks impl√©ment√©s
* ‚úÖ D√©pendances ordonn√©es
* ‚úÖ Logs structur√©s et rotation

== Ce qu'on a appris

[%step]
* S√©curiser une application Docker de bout en bout
* Scanner et corriger les vuln√©rabilit√©s
* G√©rer les secrets correctement
* Configurer pour la production
* Distribuer via registres

== SecureVote : Avant/Apr√®s

[.columns]
====
[.column]
--
**Avant :**

* Images non scann√©es
* Root partout
* Secrets en clair
* Pas de limites
--

[.column]
--
**Apr√®s :**

* Images slim, scann√©es
* Utilisateurs d√©di√©s
* Secrets prot√©g√©s
* Production-ready ‚úÖ
--
====

== üîß Troubleshooting Production

[.notes]
--
Section duration: 5 minutes
Practical debugging guide for common production issues
--

=== Conteneurs qui ne d√©marrent pas

**√âtape 1** : V√©rifier les logs

[source,bash]
----
docker logs nom-conteneur

# OU pour suivre en temps r√©el
docker logs -f nom-conteneur
----

**√âtape 2** : Inspecter le conteneur

[source,bash]
----
docker inspect nom-conteneur

# Voir seulement l'√©tat
docker inspect --format='{{.State.Status}}' nom-conteneur

# Voir le code de sortie
docker inspect --format='{{.State.ExitCode}}' nom-conteneur
----

**Probl√®mes courants** :

[cols="2,3,2", options="header"]
|===
| Sympt√¥me
| Cause probable
| Solution

| `host not found in upstream`
| NGINX : r√©solution DNS statique
| Utiliser variables : `set $backend "app:8080"` + `proxy_pass http://$backend`

| `cannot assign requested address`
| Port d√©j√† utilis√©
| Changer port ou arr√™ter service conflictuel

| `no such file or directory`
| Volume mal configur√©
| V√©rifier chemin absolu dans volumes

| `permission denied`
| Probl√®me permissions fichier
| V√©rifier propri√©taire et chmod
|===

=== Health Checks qui √©chouent

**√âtape 1** : V√©rifier le status des services

[source,bash]
----
docker compose ps

# Voir seulement les unhealthy
docker compose ps | grep unhealthy
----

**√âtape 2** : Inspecter le health check

[source,bash]
----
docker inspect nom-conteneur | grep -A 20 Health

# Voir uniquement le status
docker inspect --format='{{.State.Health.Status}}' nom-conteneur

# Voir les derniers logs du health check
docker inspect --format='{{json .State.Health.Log}}' nom-conteneur | jq
----

**Codes de sortie importants** :

* **0** : Health check r√©ussi ‚úÖ
* **1** : Health check √©chou√© (erreur applicative)
* **127** : Commande non trouv√©e (outil manquant dans l'image)
* **137** : Tu√© par signal (timeout)

**Probl√®mes courants** :

[source,text]
----
ExitCode: 127
Output: "/bin/sh: curl: not found"
‚Üí Solution : Installer curl dans Dockerfile
----

[source,text]
----
ExitCode: 1
Output: "Connection refused"
‚Üí Solution : V√©rifier que l'app √©coute sur le bon port
----

=== Debugging avec Docker Events

Surveiller tous les √©v√©nements Docker en temps r√©el :

[source,bash]
----
# Voir tous les √©v√©nements
docker events

# Filtrer par conteneur
docker events --filter container=nom-conteneur

# Filtrer par type d'√©v√©nement
docker events --filter event=start
docker events --filter event=die
docker events --filter event=health_status

# Combiner plusieurs filtres
docker events --filter container=backend --filter event=health_status
----

**Exemple de sortie** :

[source,text]
----
2026-01-12T10:30:15 container health_status: unhealthy (name=backend)
2026-01-12T10:30:20 container die (name=backend, exitCode=137)
2026-01-12T10:30:25 container start (name=backend)
----

**Utilisation pratique** :

[source,bash]
----
# Dans un terminal, monitorer les √©v√©nements
docker events --filter event=health_status

# Dans un autre terminal, d√©marrer les services
docker compose up -d

# Observer en temps r√©el les changements de sant√©
----

=== üìä Checklist de Debugging

Quand un probl√®me survient en production :

[%step]
1. ‚úÖ `docker compose ps` ‚Üí Identifier les services en erreur
2. ‚úÖ `docker logs <service>` ‚Üí Lire les logs d'erreur
3. ‚úÖ `docker inspect <service>` ‚Üí V√©rifier la configuration
4. ‚úÖ Si unhealthy : `docker inspect` pour voir Health.Log
5. ‚úÖ `docker events` en parall√®le pour monitoring temps r√©el

[TIP]
====
**Commande magique de debugging** :

[source,bash]
----
docker compose ps && \
docker compose logs --tail=50 && \
docker events --filter type=container
----

Affiche : statuts, logs r√©cents, et √©coute les √©v√©nements !
====

== Aller plus loin

[%step]
* **Orchestration** : Kubernetes, Docker Swarm
* **Secrets Management** : Vault, Sealed Secrets
* **Image Signing** : Docker Content Trust, Cosign
* **Runtime Security** : Falco, Aqua Security

== Ressources utiles

* Docker Security: https://docs.docker.com/engine/security/
* CIS Docker Benchmark
* Trivy: https://github.com/aquasecurity/trivy
* OWASP Docker Security Cheat Sheet

[{invert}]
== Fin de la session

Bravo, vous avez transform√© SecureVote en application s√©curis√©e et production-ready !

[.notes]
--
Questions et discussion finale
Retours sur exp√©rience
Difficult√©s rencontr√©es
--

== Questions ?

image::questions-docker.png[height=400px]

{author_mail}
