# Phase 3 : Production - SecureVote (1h)

## Objectif

Optimiser SecureVote pour un environnement de production : ressources, rÃ©silience, monitoring.

## PrÃ©requis

- Avoir complÃ©tÃ© la Phase 2
- Application sÃ©curisÃ©e fonctionnelle

## Vue d'ensemble des optimisations

Cette phase ajoute :
- âœ… Limites de ressources CPU/RAM
- âœ… Politiques de redÃ©marrage automatique
- âœ… Health checks applicatifs
- âœ… DÃ©pendances avec conditions de santÃ©
- âœ… Logs optimisÃ©s avec rotation
- âœ… Tests de charge et rÃ©silience

## Exercice 4 : Limites de ressources (20 min)

### Objectif
DÃ©finir des limites appropriÃ©es pour Ã©viter qu'un conteneur monopolise le serveur.

### Ã‰tape 1 : Observer la consommation actuelle

```bash
cd ../phase2

# DÃ©marrer l'application
docker compose up -d

# Observer en temps rÃ©el (laisser tourner quelques minutes)
docker stats

# RÃ©sultats typiques :
# CONTAINER         CPU %    MEM USAGE / LIMIT
# backend           5-15%    150-200 MiB
# frontend          1-3%     50-80 MiB
# database          2-8%     40-60 MiB
# cache             0-2%     10-20 MiB
# proxy             1-2%     5-10 MiB
```

### Ã‰tape 2 : Effectuer un test de charge

```bash
# Donner les droits d'exÃ©cution au script
chmod +x ../phase3/scripts/load_test.sh

# Lancer le test (100 votes, 10 en parallÃ¨le)
../phase3/scripts/load_test.sh http://localhost:8080 100 10

# Observer les ressources pendant le test
docker stats --no-stream
```

### Ã‰tape 3 : DÃ©finir les limites

BasÃ© sur l'observation, dÃ©finir des limites avec 30-50% de marge.

Dans `docker-compose.yml`, ajoutez pour chaque service :

```yaml
services:
  backend:
    deploy:
      resources:
        limits:
          cpus: '1.0'      # Maximum 1 CPU
          memory: 512M     # Maximum 512 Mo
        reservations:
          cpus: '0.25'     # Minimum garanti
          memory: 256M
```

**Limites recommandÃ©es :**

| Service  | CPU Limit | Memory Limit | CPU Reserve | Memory Reserve |
|----------|-----------|--------------|-------------|----------------|
| database | 0.5       | 512M         | 0.25        | 256M           |
| cache    | 0.25      | 256M         | 0.1         | 128M           |
| backend  | 1.0       | 512M         | 0.25        | 256M           |
| frontend | 0.5       | 256M         | 0.1         | 128M           |
| proxy    | 0.5       | 128M         | 0.1         | 64M            |

### Ã‰tape 4 : Tester avec les limites

```bash
cd ../phase3

# Copier le .env de phase2
cp ../phase2/.env .

# DÃ©marrer avec les nouvelles limites
docker compose up -d

# VÃ©rifier que les limites sont appliquÃ©es
docker stats

# Relancer le test de charge
./scripts/load_test.sh http://localhost:8080 200 20
```

### Ã‰tape 5 : Tester le dÃ©passement

Simuler une fuite mÃ©moire ou charge excessive :

```bash
# GÃ©nÃ©rer une charge CPU sur le backend
docker compose exec backend sh -c "yes > /dev/null" &

# Observer : le CPU ne doit pas dÃ©passer la limite
docker stats --no-stream

# ArrÃªter la charge
docker compose restart backend
```

### Validation

- âœ… Limites dÃ©finies pour tous les services
- âœ… Application fonctionne normalement
- âœ… Test de charge rÃ©ussi
- âœ… Les services ne dÃ©passent pas leurs limites

### Points clÃ©s
- Limites = protection du systÃ¨me
- RÃ©servations = garanties pour le service
- Toujours tester sous charge rÃ©elle
- Ajuster selon les besoins observÃ©s

## Exercice 5 : Restart et Health Checks (25 min)

### Objectif
Configurer l'auto-healing pour que les services redÃ©marrent automatiquement en cas de problÃ¨me.

### Ã‰tape 1 : Politiques de redÃ©marrage

Ajoutez Ã  chaque service :

```yaml
services:
  backend:
    restart: on-failure:5  # RedÃ©marre max 5 fois si erreur

  database:
    restart: unless-stopped  # Toujours sauf si arrÃªt manuel

  proxy:
    restart: unless-stopped
```

**Quand utiliser quelle politique ?**

- `on-failure:N` : Services applicatifs (backend, frontend)
- `unless-stopped` : Services d'infrastructure (DB, cache, proxy)
- `no` : Services temporaires, jobs
- `always` : Rarement utilisÃ© (redÃ©marre mÃªme aprÃ¨s `docker compose down`)

### Ã‰tape 2 : Health Checks PostgreSQL

```yaml
database:
  healthcheck:
    test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-dbuser} -d ${DB_NAME:-securevote}"]
    interval: 10s    # VÃ©rifier toutes les 10s
    timeout: 5s      # Timeout aprÃ¨s 5s
    retries: 5       # 5 Ã©checs avant unhealthy
    start_period: 10s # Attendre 10s au dÃ©marrage
```

### Ã‰tape 3 : Health Checks Redis

```yaml
cache:
  healthcheck:
    test: ["CMD", "redis-cli", "--raw", "-a", "${REDIS_PASSWORD}", "incr", "ping"]
    interval: 10s
    timeout: 3s
    retries: 5
    start_period: 5s
```

### Ã‰tape 4 : Health Check Backend

Le backend doit vÃ©rifier ses dÃ©pendances. Dans `app.py` :

```python
@app.route('/health')
def health():
    """Endpoint de santÃ© complet"""
    status = {"status": "healthy", "checks": {}}
    http_code = 200

    # VÃ©rifier PostgreSQL
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        cur.execute("SELECT 1")
        cur.close()
        conn.close()
        status["checks"]["database"] = "ok"
    except Exception as e:
        status["checks"]["database"] = f"error: {str(e)}"
        status["status"] = "unhealthy"
        http_code = 503

    # VÃ©rifier Redis
    try:
        redis_client.ping()
        status["checks"]["cache"] = "ok"
    except Exception as e:
        status["checks"]["cache"] = f"error: {str(e)}"
        status["status"] = "unhealthy"
        http_code = 503

    return jsonify(status), http_code
```

Dans `docker-compose.yml` :

```yaml
backend:
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 40s  # Temps pour init DB
```

### Ã‰tape 5 : Health Check Frontend

```yaml
frontend:
  healthcheck:
    test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 30s
```

### Ã‰tape 6 : Health Check Proxy

```yaml
proxy:
  healthcheck:
    test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
    interval: 30s
    timeout: 5s
    retries: 3
    start_period: 10s
```

### Ã‰tape 7 : Tester les Health Checks

```bash
# RedÃ©marrer avec les healthchecks
docker compose up -d

# Attendre que tous soient healthy
docker compose ps

# Devrait afficher (healthy) pour tous les services
# NAME                 STATUS
# securevote-backend   Up (healthy)
# securevote-db        Up (healthy)
# ...

# Tester manuellement le endpoint
curl http://localhost:8080/health
# {"status":"healthy","checks":{"database":"ok","cache":"ok"}}
```

### Ã‰tape 8 : Tester le redÃ©marrage automatique

```bash
# Donner les droits au script de test
chmod +x scripts/kill_test.sh

# Lancer le test de rÃ©silience
./scripts/kill_test.sh

# Observe :
# - Les conteneurs sont tuÃ©s brutalement
# - Ils redÃ©marrent automatiquement
# - Redeviennent healthy aprÃ¨s quelques secondes
```

Test manuel :

```bash
# Tuer le backend
docker compose kill backend

# Observer le redÃ©marrage automatique
watch -n 1 docker compose ps

# Dans quelques secondes, le backend doit Ãªtre "Up (healthy)"
```

### Validation

- âœ… Tous les services ont une politique de restart
- âœ… Tous les services ont un healthcheck
- âœ… Les services redÃ©marrent automatiquement aprÃ¨s un crash
- âœ… Les healthchecks retournent "healthy"

### Points clÃ©s
- Health checks = dÃ©tection automatique des problÃ¨mes
- L'endpoint /health doit Ãªtre simple et rapide
- Tester rÃ©ellement les dÃ©pendances critiques
- start_period = temps pour l'initialisation

## Exercice 6 : DÃ©pendances et ordre de dÃ©marrage (15 min)

### Objectif
Garantir que les services dÃ©marrent dans le bon ordre et seulement si leurs dÃ©pendances sont prÃªtes.

### Ã‰tape 1 : DÃ©finir les dÃ©pendances avec conditions

```yaml
backend:
  depends_on:
    database:
      condition: service_healthy  # Attendre que la DB soit healthy
    cache:
      condition: service_healthy  # Attendre que Redis soit healthy

frontend:
  depends_on:
    backend:
      condition: service_healthy  # Attendre que le backend soit healthy

proxy:
  depends_on:
    frontend:
      condition: service_healthy
    backend:
      condition: service_healthy
```

### Ã‰tape 2 : Tester l'ordre de dÃ©marrage

```bash
# ArrÃªter tout
docker compose down

# DÃ©marrer tout
docker compose up -d

# Observer l'ordre de dÃ©marrage dans les logs
docker compose logs -f

# Ordre attendu :
# 1. database et cache dÃ©marrent
# 2. Attendent d'Ãªtre healthy
# 3. backend dÃ©marre
# 4. Attend d'Ãªtre healthy
# 5. frontend dÃ©marre
# 6. Attend d'Ãªtre healthy
# 7. proxy dÃ©marre
```

### Ã‰tape 3 : Tester avec une dÃ©pendance cassÃ©e

```bash
# ArrÃªter la DB
docker compose stop database

# Essayer de dÃ©marrer le backend
docker compose up backend

# RÃ©sultat : Le backend attend que la DB soit healthy
# Il ne dÃ©marre pas tant que la DB n'est pas disponible
```

### Validation

- âœ… Services dÃ©marrent dans le bon ordre
- âœ… Chaque service attend que ses dÃ©pendances soient healthy
- âœ… Pas d'erreurs de connexion au dÃ©marrage

### Points clÃ©s
- `condition: service_healthy` est crucial en production
- Ã‰vite les erreurs "connection refused" au dÃ©marrage
- Garantit une initialisation propre

## Exercice 7 : Logs optimisÃ©s (Bonus si temps)

### Objectif
Ã‰viter que les logs ne remplissent le disque.

### Configuration des logs

```yaml
backend:
  logging:
    driver: "json-file"
    options:
      max-size: "10m"      # Max 10 Mo par fichier
      max-file: "3"        # Garder 3 fichiers
      labels: "service=backend,env=production"
```

### Tester la rotation

```bash
# GÃ©nÃ©rer beaucoup de logs
for i in {1..1000}; do
  curl http://localhost:8080/api/options > /dev/null 2>&1
done

# VÃ©rifier la taille des logs
docker inspect --format='{{.LogPath}}' securevote-backend
ls -lh /var/lib/docker/containers/*/securevote-backend*-json.log
```

## RÃ©capitulatif Phase 3

### Avant (Phase 2) âš ï¸
- Pas de limites de ressources
- RedÃ©marrage manuel
- Pas de health checks
- Ordre de dÃ©marrage non garanti
- Logs non limitÃ©s

### AprÃ¨s (Phase 3) âœ…
- Limites CPU/RAM pour chaque service
- Auto-healing avec politiques de restart
- Health checks complets
- DÃ©marrage ordonnÃ© avec conditions
- Logs avec rotation automatique

## Tests de validation finale

```bash
# 1. VÃ©rifier les limites
docker stats --no-stream

# 2. VÃ©rifier les health checks
docker compose ps
# Tous doivent Ãªtre (healthy)

# 3. Test de charge
./scripts/load_test.sh http://localhost:8080 300 30

# 4. Test de rÃ©silience
./scripts/kill_test.sh

# 5. VÃ©rifier les logs
docker compose logs --tail=20

# 6. Tester l'application
curl http://localhost:8080/api/options
curl http://localhost:8080/api/results
```

## MÃ©triques de succÃ¨s

| CritÃ¨re | Objectif | Validation |
|---------|----------|------------|
| DisponibilitÃ© | >99% | âœ… Auto-healing fonctionne |
| Temps de rÃ©cupÃ©ration | <30s | âœ… Restart rapide |
| Utilisation CPU | <80% sous charge | âœ… Limites respectÃ©es |
| Utilisation RAM | <512M par service | âœ… Pas de fuite mÃ©moire |
| Healthchecks | 100% healthy | âœ… Tous les services OK |

## Configuration finale production-ready

Votre application SecureVote est maintenant :

âœ… **SÃ©curisÃ©e**
- Images scannÃ©es et optimisÃ©es
- Utilisateurs non-root
- Secrets protÃ©gÃ©s
- RÃ©seaux isolÃ©s

âœ… **Robuste**
- Auto-healing
- Health checks complets
- DÃ©pendances gÃ©rÃ©es
- Gestion d'erreur

âœ… **OptimisÃ©e**
- Limites de ressources
- Logs sous contrÃ´le
- Performance validÃ©e
- Monitoring prÃªt

## Commandes de monitoring

```bash
# Voir l'Ã©tat global
docker compose ps

# Statistiques en temps rÃ©el
docker stats

# Logs en temps rÃ©el
docker compose logs -f

# Logs d'un service spÃ©cifique
docker compose logs -f backend

# Inspecter la santÃ©
curl http://localhost:8080/health | python3 -m json.tool

# RedÃ©marrer un service
docker compose restart backend

# Reconstruire et redÃ©ployer
docker compose up -d --build
```

## Aller plus loin

Pour un environnement de production rÃ©el, envisagez :

1. **Orchestration** : Kubernetes pour multi-nÅ“uds
2. **Monitoring** : Prometheus + Grafana
3. **Logs centralisÃ©s** : ELK Stack ou Loki
4. **Alertes** : Alertmanager
5. **Backup** : StratÃ©gie de sauvegarde DB
6. **SSL/TLS** : Certificats avec Let's Encrypt
7. **CI/CD** : DÃ©ploiement automatisÃ©
8. **Load balancing** : NGINX ou HAProxy multi-instances

## Conclusion

ğŸ‰ **FÃ©licitations !** Vous avez transformÃ© une application vulnÃ©rable en dÃ©ploiement production-ready !

**Ce que vous avez appris :**
- Scanner et corriger les vulnÃ©rabilitÃ©s
- Appliquer le principe du moindre privilÃ¨ge
- ProtÃ©ger les secrets
- Limiter les ressources
- ImplÃ©menter l'auto-healing
- Garantir l'ordre de dÃ©marrage
- Optimiser les logs

**Checklist finale :**
- âœ… Images lÃ©gÃ¨res et scannÃ©es
- âœ… Utilisateurs non-root
- âœ… Secrets dans .env
- âœ… RÃ©seau isolÃ©
- âœ… Limites de ressources
- âœ… Politiques de restart
- âœ… Health checks
- âœ… DÃ©pendances ordonnÃ©es
- âœ… Logs optimisÃ©s
- âœ… Tests de rÃ©silience validÃ©s

Votre application est prÃªte pour la production ! ğŸš€
